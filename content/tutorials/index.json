[{"uri":"https://fslab.org/001_getting-started.html","title":"Getting started\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: Getting started\ncategory: datascience\nauthors: David Zimmer\nindex: 0\n---\n*)\n\n(***condition:prepare***)\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n#r \u0022nuget: Newtonsoft.JSON\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.6\u0022\n#r \u0022nuget: FSharp.Data\u0022\n\n(***condition:ipynb***)\n#if IPYNB\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n#r \u0022nuget: Newtonsoft.JSON\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.6\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.6\u0022\n#r \u0022nuget: FSharp.Data\u0022\n#endif // IPYNB\n\n(**\n\n[![Binder]({{root}}images/badge-binder.svg)](https://mybinder.org/v2/gh/fslaborg/fslaborg.github.io/gh-pages?filepath={{fsdocs-source-basename}}.ipynb)\u0026emsp;\n[![Script]({{root}}images/badge-script.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.fsx)\u0026emsp;\n[![Notebook]({{root}}images/badge-notebook.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.ipynb)\n\n# Getting started\n\nGlad to see you here! Now that you found out and learned about FsLab, this section aims to illustrate how FsLab packages synergize and can be used to tackle\npractical data science challenges. Note that every package used througout the tutorial has its own documentation so if you are interested in Deedle (link), FSharp.Stats or Plotly.Net feel free to take a deeper dive.\n\n## Referencing packages\n\nFsLab is a meant to be a project incubation space and can be thought of as a safe heaven for both, package developers and package users by providing guidelines and tutorials. Packages provided by the community can be used on their own, in combination with other FsLab packages but also in combination with any other .netstandard 2.0 compatible package. From F# 5.0 on packages can be referenced using the following notation:\n\n\u0060\u0060\u0060fsharp\n// Packages hosted by the Fslab community\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n// third party .net packages \n#r \u0022nuget: Plotly.NET, 2.0.0-preview.6\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.6\u0022\n#r \u0022nuget: FSharp.Data\u0022\n\u0060\u0060\u0060\n\nafter referencing the packages one can access their namespaces and use provided functions. In the following example we will reference the\ntop level namespaces and then use a function provided by the FSharp.Stats package to calculate a factorial:\n*)\nopen FSharp.Stats\n\nlet factorialOf3 = SpecialFunctions.Factorial.factorial 3\n\n(*** condition: ipynb ***)\n#if IPYNB\nfactorialOf3\n#endif // IPYNB\n\n(***include-value:factorialOf3***)\n\n(**\n## Data access\nEquipped with these packages we are now ready to tackle promises made in the first paragraph: solving a practical data science problem. We will start by retrieving the data using the FSharp.Data package, subsequently we will use Deedle (link), a powerful data frame library that makes tabular data accessible by data frame programming. (Note that the chosen names give insight on their type, however thanks to FSharp being a strongly typed language and the we can at any time hower over single values to see the assigned type.)\n*)\nopen FSharp.Data\nopen Deedle\n\n// Retrieve data using the FSharp.Data package\nlet rawData = Http.RequestString @\u0022https://raw.githubusercontent.com/dotnet/machinelearning/master/test/data/housing.txt\u0022\n\n// And create a data frame object using the ReadCsvString method provided by Deedle.\n// Note: Of course you can directly provide the path to a local source.\nlet df = Frame.ReadCsvString(rawData,hasHeaders=true,separators=\u0022\\t\u0022)\n\n// Using the Print() method, we can use the Deedle pretty printer to have a look at the data set.\ndf.Print()\n\n(*** include-output ***)\n\n(**\n## Data crunching\nThe data set of choice is the boston housing data set. As you can see from analyzing the printed output, it consists of 506 rows. Each row represents a house in the boston city area and each column encodes a feature/variable, such as the number of rooms per dwelling (RoomsPerDwelling), Median value of owner-occupied homes in $1000\u0027s (MedianHomeValue) and even variables indicating if the house is bordering river charles (CharlesRiver, value = 1) or not (CharlesRiver, value = 0). \n\nLets say in our analysis we are only interested in the variables just described, furthermore we only want to keep rows where the value of the indicator variable is 0. We can use Deedle to easily create a new frame that fullfills our criteria. In this example we also cast the value of the column \u0022CharlesRiver\u0022 to be of type bool, this illustrates how data frame programming can become typesafe using deedle.\n*)\n\nlet housesNotAtRiver = \n    df\n    |\u003E Frame.sliceCols [\u0022RoomsPerDwelling\u0022;\u0022MedianHomeValue\u0022;\u0022CharlesRiver\u0022]\n    |\u003E Frame.filterRowValues (fun s -\u003E s.GetAs\u003Cbool\u003E(\u0022CharlesRiver\u0022) |\u003E not ) \n\n//sprintf \u0022The new frame does now contain: %i rows and %i columns\u0022 housesNotAtRiver.RowCount housesNotAtRiver.ColumnCount\n\nhousesNotAtRiver.Print()\n\n(*** include-output ***)\n\n(**\n## Data exploration\n\nExploratory data analysis is an approach favored by many - to meet this demand we strongly advertise the use of Plotly.Net. The following snippet illustrates how we can access a column of a data frame and create an interactive chart in no time. Since we might want an idea of the distribution of the house prices a histogram can come in handy: \n*)\nopen Plotly.NET\n\n// Note that we explicitly specify that we want to work with the values as floats. \n// Since the row identity is not needed anymore when plotting the distribution we can\n// directly convert the collection to a FSharp Sequence. \nlet pricesNotAtRiver : seq\u003Cfloat\u003E = \n    housesNotAtRiver\n    |\u003E Frame.getCol \u0022MedianHomeValue\u0022\n    |\u003E Series.values\n    \nlet h1 = \n    Chart.Histogram(pricesNotAtRiver)\n    |\u003E Chart.withX_AxisStyle(\u0022median value of owner occupied homes in 1000s\u0022)\n    |\u003E Chart.withX_AxisStyle(\u0022price distribution\u0022)\n\n(*** condition: ipynb ***)\n#if IPYNB\nh1\n#endif // IPYNB\n\n(***hide***)\nh1 |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\nSince plotly charts are interactive they invite us to combine mutliple charts. Let repeat the filter step and see if houses that are located at the river show a similar distribution:\n*)\n\nlet housesAtRiver = \n    df\n    |\u003E Frame.sliceCols [\u0022RoomsPerDwelling\u0022;\u0022MedianHomeValue\u0022;\u0022CharlesRiver\u0022]\n    |\u003E Frame.filterRowValues (fun s -\u003E s.GetAs\u003Cbool\u003E(\u0022CharlesRiver\u0022))\n\nlet pricesAtRiver : seq\u003Cfloat\u003E = \n    housesAtRiver\n    |\u003E Frame.getCol \u0022MedianHomeValue\u0022\n    |\u003E Series.values\n\nlet h2 =     \n    [\n    Chart.Histogram(pricesNotAtRiver)\n    |\u003E Chart.withTraceName \u0022not at river\u0022\n    Chart.Histogram(pricesAtRiver)\n    |\u003E Chart.withTraceName \u0022at river\u0022\n    ]\n    |\u003E Chart.Combine\n    |\u003E Chart.withX_AxisStyle(\u0022median value of owner occupied homes in 1000s\u0022)\n    |\u003E Chart.withX_AxisStyle(\u0022Comparison of price distributions\u0022)\n\n(***hide***)\nh2 |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\nThe interactive chart allows us to compare the distributions directly. We can now reconstruct our own idea of the city of boston, the sampled area, just by looking at the data e.g.:\n\nAssuming that the sampling process was homogenous while observing that there are much more houses sampled that are not located on the riverside could indicate that a spot on the river is a scarce commodity.\nThis could also be backed by analyzing the tails of the distribution: it seems that houses located at the river are given a head-start in their assigned value - the distribution of the riverside houses is truncated on the left. \n\nSuppose we would have a customer that wants two models, one to predict the prices of a house at the riverside and one that predicts the prices if this is not the case, then we can meet this demand by using FSharp.Stats in combination with Deedle. Of course we need a variable that is indicative of the house price, in this we will check if the number of rooms per dwelling correlates with the house value:\n*)\n\nlet pricesAll :Series\u003Cint,float\u003E = \n    df\n    |\u003E Frame.getCol \u0022MedianHomeValue\u0022\n\nlet roomsPerDwellingAll :Series\u003Cint,float\u003E = \n    df\n    |\u003E Frame.getCol \u0022RoomsPerDwelling\u0022   \n\nlet correlation = \n    let tmpPrices,tmpRooms = \n        Series.zipInner pricesAll roomsPerDwellingAll    \n        |\u003E Series.values \n        |\u003E Seq.unzip\n    Correlation.Seq.pearson tmpPrices tmpRooms\n                                              \n(***include-value:correlation***)\n\n(**\nSo indeed, the number of rooms per dwelling shows a positiv correlation with the house prices. With a pearson correlation of ~0.7 it does not explain the house prices completely - but this is nothing that really surprises us, as one of our hypothesis is that the location (e.g. riverside) does also have influence on the price -  however, it should be sufficient to create a linear model. \n\nSo now we will use FSharp.Stats to build the two linear models ordered by the hypothetical customer. We start by defining a function that performs the fitting and plots the result:\n*)\n\nopen Fitting.LinearRegression.OrdinaryLeastSquares\n\nlet predictPricesByRooms description data = \n    let pricesAll :Series\u003C_,float\u003E = \n        data\n        |\u003E Frame.getCol \u0022MedianHomeValue\u0022\n\n    let roomsPerDwellingAll :Series\u003C_,float\u003E = \n        data\n        |\u003E Frame.getCol \u0022RoomsPerDwelling\u0022   \n\n    let fit = \n        let tmpRooms, tmpPrices = \n            Series.zipInner roomsPerDwellingAll pricesAll    \n            |\u003E Series.sortBy fst\n            |\u003E Series.values \n            |\u003E Seq.unzip\n        let coeffs = Linear.Univariable.coefficient (vector tmpRooms) (vector tmpPrices)\n        let model  = Linear.Univariable.fit coeffs \n        let predictedPrices = tmpRooms |\u003E Seq.map model\n        [\n        Chart.Point(tmpRooms,tmpPrices)\n        |\u003E Chart.withTraceName (sprintf \u0022%s: data\u0022 description )\n        Chart.Line(tmpRooms,predictedPrices)\n        |\u003E Chart.withTraceName (sprintf \u0022%s: coefficients: intercept:%f, slope:%f\u0022 description coeffs.[0] coeffs.[1])\n        ]                                  \n        |\u003E Chart.Combine\n        |\u003E Chart.withX_AxisStyle(\u0022rooms per dwelling\u0022)\n        |\u003E Chart.withY_AxisStyle(\u0022median value\u0022)\n    fit   \n\n(**\nAfterwards, we can apply the function on our prepared datasets and have a look at the model and especially the model coefficients. \n*)\nlet modelVis = \n    [\n    predictPricesByRooms \u0022not at river\u0022 housesNotAtRiver\n    predictPricesByRooms \u0022at river\u0022 housesAtRiver\n    ]\n    |\u003E Chart.Combine\n    |\u003E Chart.withSize(1200.,700.)\n\n(***hide***)\nmodelVis |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n\n(**\nBoth models approximate the data in a reasonable way. When we inspect the coefficients, we see that the models only differ slightly in slope, but have an absolute offset of ~7.5. This observation complements the insights gained by the explorative data analysis approach using the histogram! \n*)"},{"uri":"https://fslab.org/external.html","title":"Here is a list of usefull external (non-fslab) F# resources:\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: External F# resources\ncategory: fsharp\nauthors: Various\nindex: 0\n---\n*)\n\n(**\n# Here is a list of usefull external (non-fslab) F# resources:\n\n## Learning and documentation\n- Official F# documentation: https://docs.microsoft.com/en-us/dotnet/fsharp/\n- F# module on Microsoft LEARN: https://docs.microsoft.com/en-us/learn/modules/fsharp-first-steps/\n- Website of the F# Software Foundation: https://fsharp.org/\n\n## Blogs \u0026 other content\n- fsharp for fun and profit: https://fsharpforfunandprofit.com/\n- fsharp weekly: https://sergeytihon.com/category/f-weekly/\n\n*)"},{"uri":"https://fslab.org/003_clustering_hierarchical.html","title":"Clustering with FSharp.Stats II: hierarchical clustering\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: Clustering with FSharp.Stats II: hierarchical clustering\ncategory: datascience\nauthors: Benedikt Venn\nindex: 2\n---\n*)\n\n(***condition:prepare***)\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n#r \u0022nuget: Newtonsoft.JSON\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.6\u0022\n#r \u0022nuget: FSharp.Data\u0022\n\n(***condition:ipynb***)\n#if IPYNB\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n#r \u0022nuget: Newtonsoft.JSON\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.6\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.6\u0022\n#r \u0022nuget: FSharp.Data\u0022\n#endif // IPYNB\n\n\n(**\n\n[![Binder]({{root}}images/badge-binder.svg)](https://mybinder.org/v2/gh/fslaborg/fslaborg.github.io/gh-pages?filepath={{fsdocs-source-basename}}.ipynb)\u0026emsp;\n[![Script]({{root}}images/badge-script.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.fsx)\u0026emsp;\n[![Notebook]({{root}}images/badge-notebook.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.ipynb)\n\n# Clustering with FSharp.Stats II: hierarchical clustering\n\n_Summary:_ This tutorial demonstrates hierarchical clustering with FSharp.Stats and how to visualize the results with Plotly.NET.\n\nIn the previous article of this series [k-means clustering using FSharp.Stats](https://fslab.org/content/tutorials/002_clustering_kMeans.html) was introduced.\n\n## Introduction\n\nClustering methods can be used to group elements of a huge data set based on their similarity. Elements sharing similar properties cluster together and can be reported as coherent group.\nMany clustering algorithms require a predefined cluster number, that has to be provided by the experimenter.\nHierarchical clustering (hClust) does not require such cluster number definition. Instead, hierarchical clustering results in a tree structure, that has a single cluster (node) on its root and recursively splits up into clusters of \nelements that are more similar to each other than to elements of other clusters. For generating multiple clustering results with different number of clusters, \nthe clustering has to performed only once. Subsequently a cluster number can be defined to split up the clustering tree in the desired number of clusters.\nThe clustering tree is often represented as dendrogram.\n\n### There are two types of hClust:\n\n  - Agglomerative (bottom-up): Each data point is in its own cluster and the nearest ones are merged recursively. It is referred as agglomerative hierarchical clustering.\n\n  - Divisive (top-down): All data points are in the same cluster and you divide the cluster into two that are far away from each other.\n\n  - The presented implementation is an agglomerative type.\n\n### Distance measures\n\nThere are several distance metrics, that can be used as distance function. The commonly used one probably is Euclidean distance.\n\n### Linker\n\nWhen the distance between two clusters is calculated, there are several linkage types to choose from:\n\n  - **complete linkage**: maximal pairwise distance between the clusters (prone to break large clusters)\n\n  - **single linkage**: minimal pairwise distance between the clusters (sensitive to outliers)\n\n  - **centroid linkage**: distance between the two cluster centroids\n\n  - **average linkage**: average pairwise distance between the clusters (sensitive to cluster shape and size)\n\n  - **median linkage**: median pairwise distance between the clusters\n\n\u003Ccenter\u003E\n\u003Cimg style=\u0022max-width:85%\u0022 src=\u0022../../images/hClust.png\u0022\u003E\u003C/img\u003E\n\u003C/center\u003E\n\u003Cbr\u003E\n\n\nFor demonstration of hierarchical clustering, the classic iris data set is used, which consists of 150 records, each of which contains four measurements and a species identifier.\n\n## Referencing packages\n\n\u0060\u0060\u0060fsharp\n// Packages hosted by the Fslab community\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n// third party .net packages \n#r \u0022nuget: Plotly.NET, 2.0.0-preview.6\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.6\u0022\n#r \u0022nuget: FSharp.Data\u0022\n\u0060\u0060\u0060\n\n*)\n\n(**\n## Loading data\n*)\nopen FSharp.Data\nopen Deedle\n\n// Retrieve data using the FSharp.Data package and read it as dataframe using the Deedle package\nlet rawData = Http.RequestString @\u0022https://raw.githubusercontent.com/fslaborg/datasets/main/data/iris.csv\u0022\nlet df = Frame.ReadCsvString(rawData)\n\ndf.Print()\n\n\n(*** include-output ***)\n\n(**\n\nLet\u0027s take a first look at the data with heatmaps using Plotly.NET. Each of the 150 records consists of four measurements and a species identifier. \nSince the species identifier occur several times (Iris-virginica, Iris-versicolor, and Iris-setosa), we create unique labels by adding the rows index to the species identifier.\n\n*)\nopen Plotly.NET\n\nlet colNames = [\u0022sepal_length\u0022;\u0022sepal_width\u0022;\u0022petal_length\u0022;\u0022petal_width\u0022]\n\n// isolate data as float [] []\nlet data = \n    Frame.dropCol \u0022species\u0022 df\n    |\u003E Frame.toJaggedArray\n    \n\n// isolate labels as seq\u003Cstring\u003E\nlet labels = \n    Frame.getCol \u0022species\u0022 df\n    |\u003E Series.values\n    |\u003E Seq.mapi (fun i s -\u003E sprintf \u0022%s_%i\u0022 s i)\n    |\u003E Array.ofSeq\n\nlet dataChart = \n    Chart.Heatmap(data,ColNames=colNames,RowNames=labels)\n    // required to fit the species identifier on the left side of the heatmap\n    |\u003E Chart.withMarginSize(Left=100.)\n    |\u003E Chart.withTitle \u0022raw iris data\u0022\n\n(**\n\u003Ccenter\u003E\n*)\n(*** condition: ipynb ***)\n#if IPYNB\ndataChart\n#endif // IPYNB\n\n(***hide***)\ndataChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\u003C/center\u003E\n## Clustering\n\nThe function that performs hierarchical clustering can be found at \u0060FSharp.Stats.ML.Unsupervised.HierarchicalClustering.generate\u0060. It requires three input parameters:\n\n  1. Distance measure working on \u0060\u0027T\u0060 (from \u0060FSharp.Stats.ML.DistanceMetrics\u0060)\n  2. Linkage type\n  3. Data to cluster as \u0060\u0027T\u0060\n\n*)\n\nopen FSharp.Stats.ML\nopen FSharp.Stats.ML.Unsupervised\n\nlet distanceMeasure = DistanceMetrics.euclideanNaNSquared\n\nlet linker = HierarchicalClustering.Linker.centroidLwLinker\n\n// calculates the clustering and reports a single root cluster (node), \n// that may recursively contains further nodes\nlet clusterResultH = \n    HierarchicalClustering.generate distanceMeasure linker data\n\n// If a desired cluster number is specified, the following function cuts the cluster according\n// to the depth, that results in the respective number of clusters (here 3). Only leaves are reported.\nlet threeClusters = HierarchicalClustering.cutHClust 3 clusterResultH\n\n(**\n\nEvery cluster leaf contains its raw values and an index that indicates the position of the respective data \npoint in the raw data. The index can be retrieved from leaves using HierarchicalClustering.getClusterId.\n\n*)\n\n// Detailed information for 3 clusters are given\nlet inspectThreeClusters =\n    threeClusters\n    |\u003E List.map (fun cluster -\u003E \n        cluster\n        |\u003E List.map (fun leaf -\u003E \n            labels.[HierarchicalClustering.getClusterId leaf]\n            )\n        )\n\n(*** condition: ipynb ***)\n#if IPYNB\ninspectThreeClusters\n|\u003E List.mapi (fun i x -\u003E \n    let truncCluster = x.[0..4] |\u003E String.concat \u0022; \u0022 \n    sprintf \u0022Cluster%i: [%s ...]\u0022 i truncCluster \n    )\n|\u003E String.concat \u0022\u003Cbr\u003E\u0022\n#endif // IPYNB\n\n(***hide***)\ninspectThreeClusters\n|\u003E List.mapi (fun i x -\u003E \n    let truncCluster = x.[0..4] |\u003E String.concat \u0022; \u0022 \n    sprintf \u0022Cluster%i: [%s ...]\u0022 i truncCluster \n    )\n|\u003E String.concat \u0022\u003Cbr\u003E\u0022\n(*** include-it-raw ***)\n\n(**\n\nTo break up the tree structure but maintain the clustering order, the cluster tree has to be flattened.\n\n*)\n\n// To recursevely flatten the cluster tree into leaves only, use flattenHClust.\n// A leaf list is reported, that does not contain any cluster membership, \n// but is sorted by the clustering result.\nlet hLeaves = \n    clusterResultH\n    |\u003E HierarchicalClustering.flattenHClust\n    \n// Takes the sorted cluster result and reports a tuple of label and data value.\nlet dataSortedByClustering =    \n    hLeaves\n    |\u003E Seq.choose (fun c -\u003E \n        let label  = labels.[HierarchicalClustering.getClusterId c]\n        let values = HierarchicalClustering.tryGetLeafValue c\n        match values with\n        | None -\u003E None\n        | Some x -\u003E Some (label,x)\n        )\n\n(**\n\nThe visualization again is performed using a Plotly.NET heatmap. \n        \n*)\n\nlet hClusteredDataHeatmap = \n    let (hlable,hdata) =\n        dataSortedByClustering\n        |\u003E Seq.unzip\n    Chart.Heatmap(hdata,ColNames=colNames,RowNames=hlable)\n    // required to fit the species identifier on the left side of the heatmap\n    |\u003E Chart.withMarginSize(Left=100.)\n    |\u003E Chart.withTitle \u0022Clustered iris data (hierarchical clustering)\u0022\n(**\n\u003Ccenter\u003E\n*)\n(*** condition: ipynb ***)\n#if IPYNB\nhClusteredDataHeatmap\n#endif // IPYNB\n\n(***hide***)\nhClusteredDataHeatmap |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n\n(**\n\u003C/center\u003E\n\n## Limitations\n\n  1. There is no strong guidance on which distance function and linkage type should be used. It often is chosen arbitrarily according to the user\u0027s experience.\n  2. The visual interpretation of the dendrogram is difficult, since swapping the direction of some bifurcations may totally disturbe the visual impression.\n\n## Notes\n\n  - Please note that depending on what data you want to cluster, a column wise z-score normalization may be required. In the presented example differences in sepal width have a reduced influence because\n  the absolute variation is low.\n\n## References\n\n  - Vijaya et al., A Review on Hierarchical Clustering Algorithms, Journal of Engineering and Applied Sciences, 2017\n  - Rani and Rohil, A Study of Hierarchical Clustering Algorithm, International Journal of Information and Computation Technology, 2013\n  - FSharp.Stats documentation, fslaborg, https://fslab.org/FSharp.Stats/Clustering.html\n\n## Further reading\n\nExamples are taken from [FSharp.Stats documentation](https://fslab.org/FSharp.Stats/Clustering.html) that covers various techniques for an optimal cluster number determination.\n\nThe next article in this series covers [DBSCAN using FSharp.Stats](https://fslab.org/content/tutorials/004_clustering_DBSCAN.html).\n\n*)\n\n\n"},{"uri":"https://fslab.org/advanced-placeholder.html","title":"WIP\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: Advanced placeholder\ncategory: advanced\nauthors: won\u0027t tell\nindex: 0\n---\n*)\n\n(**\n# WIP\n*)"},{"uri":"https://fslab.org/002_clustering_kMeans.html","title":"Clustering with FSharp.Stats I: k-means\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: Clustering with FSharp.Stats I: k-means\ncategory: datascience\nauthors: Benedikt Venn\nindex: 1\n---\n*)\n\n(***condition:prepare***)\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n#r \u0022nuget: Newtonsoft.JSON\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.6\u0022\n#r \u0022nuget: FSharp.Data\u0022\n\n(***condition:ipynb***)\n#if IPYNB\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n#r \u0022nuget: Newtonsoft.JSON\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.6\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.6\u0022\n#r \u0022nuget: FSharp.Data\u0022\n#endif // IPYNB\n\n(**\n\n[![Binder]({{root}}images/badge-binder.svg)](https://mybinder.org/v2/gh/fslaborg/fslaborg.github.io/gh-pages?filepath={{fsdocs-source-basename}}.ipynb)\u0026emsp;\n[![Script]({{root}}images/badge-script.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.fsx)\u0026emsp;\n[![Notebook]({{root}}images/badge-notebook.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.ipynb)\n\n\n# Clustering with FSharp.Stats I: k-means\n\n_Summary:_ This tutorial demonstrates k means clustering with FSharp.Stats and how to visualize the results with Plotly.NET.\n\n## Introduction\n\nClustering methods can be used to group elements of a huge data set based on their similarity. Elements sharing similar properties cluster together and can be reported as coherent group.\nk-means clustering is a frequently used technique, that segregates the given data into k clusters with similar elements grouped in each cluster, but high variation between the clusters.\nThe algorithm to cluster a n-dimensional dataset can be fully described in the following 4 steps:\n\n  1. Initialize k n-dimensional centroids, that are randomly distributed over the data range.\n  2. Calculate the distance of each point to all centroids and assign it to the nearest one.\n  3. Reposition all centroids by calculating the average point of each cluster.\n  4. Repeat step 2-3 until convergence.\n\n### Centroid initiation\n\nSince the random initiation of centroids may influences the result, a second initiation algorithm is proposed (_cvmax_), that extract a set of medians from the dimension with maximum variance to initialize the centroids. \n\n### Distance measure\n\nWhile several distance metrics can be used (e.g. Manhattan distance or correlation measures) it is preferred to use Euclidean distance.\nIt is recommended to use a squared Euclidean distance. To not calculate the square root does not change the result but saves computation time.\n\n\u003Ccenter\u003E\n\u003Cimg style=\u0022max-width:75%\u0022 src=\u0022../../images/kMeans.png\u0022 class=\u0022center\u0022\u003E\u003C/img\u003E\n\u003C/center\u003E\n\u003Cbr\u003E\n\n\nFor demonstration of k-means clustering, the classic iris data set is used, which consists of 150 records, each of which contains four measurements and a species identifier.\n\n## Referencing packages\n\n\u0060\u0060\u0060fsharp\n// Packages hosted by the Fslab community\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n// third party .net packages \n#r \u0022nuget: Plotly.NET, 2.0.0-preview.6\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.6\u0022\n#r \u0022nuget: FSharp.Data\u0022\n\u0060\u0060\u0060\n\n*)\n\n(**\n## Loading data\n*)\nopen FSharp.Data\nopen Deedle\n\n// Retrieve data using the FSharp.Data package and read it as dataframe using the Deedle package\nlet rawData = Http.RequestString @\u0022https://raw.githubusercontent.com/fslaborg/datasets/main/data/iris.csv\u0022\nlet df = Frame.ReadCsvString(rawData)\n\ndf.Print()\n\n(*** include-output ***)\n\n(**\n\nLet\u0027s take a first look at the data with heatmaps using Plotly.NET. Each of the 150 records consists of four measurements and a species identifier. \nSince the species identifier occur several times (_Iris-virginica_, _Iris-versicolor_, and _Iris-setosa_), we create unique labels by adding the rows index to the species identifier.\n\n*)\nopen Plotly.NET\n\nlet colNames = [\u0022sepal_length\u0022;\u0022sepal_width\u0022;\u0022petal_length\u0022;\u0022petal_width\u0022]\n\n// isolate data as float [] []\nlet data = \n    Frame.dropCol \u0022species\u0022 df\n    |\u003E Frame.toJaggedArray\n\n//isolate labels as seq\u003Cstring\u003E\nlet labels = \n    Frame.getCol \u0022species\u0022 df\n    |\u003E Series.values\n    |\u003E Seq.mapi (fun i s -\u003E sprintf \u0022%s_%i\u0022 s i)\n\nlet dataChart = \n    Chart.Heatmap(data,ColNames=colNames,RowNames=labels)\n    // required to fit the species identifier on the left side of the heatmap\n    |\u003E Chart.withMarginSize(Left=100.)\n    |\u003E Chart.withTitle \u0022raw iris data\u0022\n\n// required to fit the species identifier on the left side of the heatmap\n(**\u003Ccenter\u003E*)\n(*** condition: ipynb ***)\n#if IPYNB\ndataChart\n#endif // IPYNB\n\n(***hide***)\ndataChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\u003C/center\u003E\n## Clustering\n\nThe function that performs k-means clustering can be found at \u0060FSharp.Stats.ML.Unsupervised.IterativeClustering.kmeans\u0060. It requires four input parameters:\n\n  1. Centroid initiation method\n  2. Distance measure (from \u0060FSharp.Stats.ML.DistanceMetrics\u0060)\n  3. Data to cluster as \u0060float [] []\u0060, where each entry of the outer array is a sequence of coordinates\n  4. _k_, the number of clusters that are desired\n\n\n*)\n\nopen FSharp.Stats\nopen FSharp.Stats.ML\nopen FSharp.Stats.ML.Unsupervised\n\n// For random cluster initiation use randomInitFactory:\nlet rnd = System.Random()\nlet randomInitFactory : IterativeClustering.CentroidsFactory\u003Cfloat []\u003E = \n    IterativeClustering.randomCentroids\u003Cfloat []\u003E rnd\n\n// For assisted cluster initiation use cvmaxFactory:\n//let cvmaxFactory : IterativeClustering.CentroidsFactory\u003Cfloat []\u003E = \n//    IterativeClustering.intitCVMAX\n\nlet distanceFunction = DistanceMetrics.euclideanNaNSquared\n  \nlet kmeansResult = \n    IterativeClustering.kmeans distanceFunction randomInitFactory data 4\n\n\n(**\nAfter all centroids are set, the affiliation of a datapoint to a cluster can be determined by minimizing the distance of the respective point to each of the centroids.\nA function realizing the mapping is integrated in the \u0060kmeansResult\u0060.\n\n*)\n\nlet clusteredIrisData =\n    Seq.zip labels data\n    |\u003E Seq.map (fun (species,dataPoint) -\u003E \n        let clusterIndex,centroid = kmeansResult.Classifier dataPoint\n        clusterIndex,species,dataPoint)\n\n// Each datapoint is given associated with its cluster index, species identifier, and coordinates.\n\n(*** condition: ipynb ***)\n#if IPYNB\nclusteredIrisData\n|\u003E Seq.take 10\n|\u003E Seq.map (fun (a,b,c) -\u003E sprintf \u0022%i, %A, %A\u0022 a b c)\n|\u003E String.concat \u0022\\n\u0022\n|\u003E String.concat \u0022\u003Cbr\u003E\u0022\n|\u003E fun x -\u003E x \u002B \u0022\u003Cbr\u003E ... \u0022\n#endif // IPYNB\n\n(***hide***)\nlet printClusters=\n    clusteredIrisData\n    |\u003E Seq.take 7\n    |\u003E Seq.map (fun (a,b,c) -\u003E sprintf \u0022%i, %A, %A\u0022 a b c)\n    |\u003E String.concat \u0022\\n\u0022\n    |\u003E fun x -\u003E x \u002B \u0022\\n ... \u0022\n\n(*** include-value:printClusters ***)\n(**\n\n## Visualization of the clustering result as heatmap\n\nThe datapoints are sorted according to their associated cluster index and visualized in a combined heatmap.\n*)\n\nlet clusterChart =\n    clusteredIrisData\n    //sort all data points according to their assigned cluster number\n    |\u003E Seq.sortBy (fun (clusterIndex,label,dataPoint) -\u003E clusterIndex)\n    |\u003E Seq.unzip3\n    |\u003E fun (_,labels,d) -\u003E \n        Chart.Heatmap(d,ColNames=colNames,RowNames=labels)\n        // required to fit the species identifier on the left side of the heatmap\n        |\u003E Chart.withMarginSize(Left=100.)\n        |\u003E Chart.withTitle \u0022clustered iris data (k-means clustering)\u0022\n(**\n\u003Ccenter\u003E\n*)\n(*** condition: ipynb ***)\n#if IPYNB\nclusterChart\n#endif // IPYNB\n\n(***hide***)\nclusterChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\u003C/center\u003E\n\nTo visualize the result in a three-dimensional chart, three of the four measurements are isolated after clustering and visualized as 3D-scatter plot.\n\n*)\n\nlet clusterChart3D =\n    //group clusters\n    clusteredIrisData\n    |\u003E Seq.groupBy (fun (clusterIndex,label,dataPoint) -\u003E clusterIndex)\n    //for each cluster generate a scatter plot\n    |\u003E Seq.map (fun (clusterIndex,cluster) -\u003E \n        cluster\n        |\u003E Seq.unzip3\n        |\u003E fun (clusterIndex,label,data) -\u003E \n            let clusterName = sprintf \u0022cluster %i\u0022 (Seq.head clusterIndex)\n            //for 3 dimensional representation isolate sepal length, petal length, and petal width\n            let truncData = data |\u003E Seq.map (fun x -\u003E x.[0],x.[2],x.[3]) \n            Chart.Scatter3d(truncData,mode=StyleParam.Mode.Markers,Name = clusterName,Labels=label)\n        )\n    |\u003E Chart.Combine\n    |\u003E Chart.withTitle \u0022isolated coordinates of clustered iris data (k-means clustering)\u0022\n    |\u003E Chart.withX_AxisStyle colNames.[0]\n    |\u003E Chart.withY_AxisStyle colNames.[2]\n    |\u003E Chart.withZ_AxisStyle colNames.[3]\n\n(**\n\u003Ccenter\u003E\n*)\n(*** condition: ipynb ***)\n#if IPYNB\nclusterChart3D\n#endif // IPYNB\n\n(***hide***)\nclusterChart3D |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\u003C/center\u003E\n\n### Optimal cluster number\n\nThe identification of the optimal cluster number _k_ in terms of the average squared distance of each point to its centroid \ncan be realized by performing the clustering over a range of _k_\u0027s multiple times and taking the _k_ according to the elbow criterion.\nFurther more robust and advanced cluster number determination techniques can be found [here](https://fslab.org/FSharp.Stats/Clustering.html#Determining-the-optimal-number-of-clusters).\n\n*)\n\nlet getBestkMeansClustering bootstraps k =\n    let dispersions =\n        Array.init bootstraps (fun _ -\u003E \n            IterativeClustering.kmeans distanceFunction randomInitFactory data k\n            )\n        |\u003E Array.map (fun clusteringResult -\u003E IterativeClustering.DispersionOfClusterResult clusteringResult)\n    Seq.mean dispersions,Seq.stDev dispersions\n\nlet iterations = 10\n\nlet maximalK = 10\n\nlet bestKChart = \n    [2 .. maximalK] \n    |\u003E List.map (fun k -\u003E \n        let mean,stdev = getBestkMeansClustering iterations k\n        k,mean,stdev\n        )\n    |\u003E List.unzip3\n    |\u003E fun (ks,means,stdevs) -\u003E \n        Chart.Line(ks,means)\n        |\u003E Chart.withYErrorStyle(stdevs)\n        |\u003E Chart.withX_AxisStyle \u0022k\u0022\n        |\u003E Chart.withY_AxisStyle \u0022average dispersion\u0022\n        |\u003E Chart.withTitle \u0022iris data set average dispersion per k\u0022\n(**\n\u003Ccenter\u003E\n*)\n(*** condition: ipynb ***)\n#if IPYNB\nbestKChart\n#endif // IPYNB\n\n(***hide***)\nbestKChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\n\u003C/center\u003E\n\n## Limitations\n\n  1. Outlier have a strong influence on the positioning of the centroids. \n  2. Determining the correct number of clusters in advance is critical. Often it is chosen according to the number of classes present in the dataset which isn\u0027t in the spirit of clustering procedures.\n\n## Notes\n\n  - Please note that depending on what data you want to cluster, a column wise z-score normalization may be required. In the presented example differences in sepal width have a reduced influence because\n  the absolute variation is low.\n\n## References\n\n  - FSharp.Stats documentation, fslaborg, https://fslab.org/FSharp.Stats/Clustering.html\n  - Shraddha and Saganna, A Review On K-means Data Clustering Approach, International Journal of Information \u0026 Computation Technology, Vol:4 No:17, 2014\n  - Moth\u0027d Belal, A New Algorithm for Cluster Initialization, International Journal of Computer and Information Engineering, Vol:1 No:4, 2007\n  - Singh et al., K-means with Three different Distance Metrics, International Journal of Computer Applications, 2013, DOI:10.5120/11430-6785\n  - Kodinariya and Makwana, Review on Determining of Cluster in K-means Clustering, International Journal of Advance Research in Computer Science and Management Studies, 2013\n\n## Further reading\n  \nExamples are taken from [FSharp.Stats documentation](https://fslab.org/FSharp.Stats/Clustering.html) that covers various techniques for an optimal cluster number determination.\n  \nThe next article in this series covers [hierarchical clustering using FSharp.Stats](https://fslab.org/content/tutorials/003_clustering_hierarchical.html).\n\n*)\n\n\n"},{"uri":"https://fslab.org/005_savitzky_golay_temperature.html","title":"Smoothing data with the Savitzky-Golay filter\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: Smoothing data with the Savitzky-Golay filter\ncategory: datascience\nauthors: Kevin Frey\nindex: 4\n---\n*)\n\n(***condition:prepare***)\n#r \u0022nuget: Fsharp.Data\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.6\u0022\n\n(***condition:ipynb***)\n#if IPYNB\n#r \u0022nuget: FSharp.Data\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n#r \u0022nuget: Newtonsoft.JSON\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.6\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.6\u0022\n#endif // IPYNB\n\n(**\n[![Binder]({{root}}images/badge-binder.svg)](https://mybinder.org/v2/gh/fslaborg/fslaborg.github.io/gh-pages?filepath={{fsdocs-source-basename}}.ipynb)\u0026emsp;\n[![Script]({{root}}images/badge-script.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.fsx)\u0026emsp;\n[![Notebook]({{root}}images/badge-notebook.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.ipynb)\n\n\n# Smoothing data with the Savitzky-Golay filter\n\n_Summary:_ This tutorial demonstrates how to access a public dataset for temperature data with [FSharp.Data](https://fsprojects.github.io/FSharp.Data/), how to smoothe the data points with \nthe Savitzky-Golay filter from [FSharp.Stats](https://fslab.org/FSharp.Stats/) and finally how to visualize the results with [Plotly.NET](https://plotly.net).\n\n## Introduction: \n\nThe Savitzky-Golay is a type of low-pass filter, particularly suited for smoothing noisy data. The main idea behind this approach is to make for each point a \nleast-square fit with a polynomial of high order over a odd-sized window centered at the point. One advantage of the Savitzky-Golay filter is that, portions \nof high frequencies are not simply cut off, but are preserved due to the polynomial regression. This allows the filter to preserve properties of the distribution \nsuch as relative maxima, minima and dispersion, which are usually distorted by flattening or shifting by conventional methods such as moving average.\n\nThis is useful when trying to identify general trends in highly fluctuating data sets, or to smooth out noise to improve the ability to find minima and maxima of the data trend.\nTo showcase this we will plot a temperature dataset from the [\u0022Deutsche Wetterdienst\u0022](https://www.dwd.de/DE/leistungen/klimadatendeutschland/klimadatendeutschland.html), \na german organization for climate data. We will do this for both the original data points and a smoothed version.\n\n\u003Ccenter\u003E\n\n![windowed polynomial regression](https://upload.wikimedia.org/wikipedia/commons/8/89/Lissage_sg3_anim.gif)\n\nThe image shows the moving window for polynomial regression used in the Savitzky-Golay filter [@wikipedia](https://upload.wikimedia.org/wikipedia/commons/8/89/Lissage_sg3_anim.gif)\n\n\u003C/center\u003E\n\n## Referencing packages\n\n\u0060\u0060\u0060fsharp\n// Packages hosted by the Fslab community\n#r \u0022nuget: FSharp.Stats\u0022\n// third party .net packages \n#r \u0022nuget: FSharp.Data\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.6\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.6\u0022\n\u0060\u0060\u0060\n\n*)\n\n\n(**\n## Loading data\n\nWe will start by retrieving the data. This is done with the [FSharp.Data](https://fsprojects.github.io/FSharp.Data/) package \nand will return a single string in the original format.\n*)\n\n// Get data from Deutscher Wetterdienst\n// Explanation for Abbreviations: https://www.dwd.de/DE/leistungen/klimadatendeutschland/beschreibung_tagesmonatswerte.html\nlet rawData = FSharp.Data.Http.RequestString @\u0022https://raw.githubusercontent.com/fslaborg/datasets/main/data/WeatherDataAachen-Orsbach_daily_1year.txt\u0022\n\n// print first 1000 characters to console.\nrawData.[..1000] |\u003E printfn \u0022%s\u0022\n\n(*** include-output ***)\n\n(**\n\nCurrently the data set is not in a format, that is easily parsable. Normally you would try to use \nthe Deedle package to read in the data into a a [Deedle](https://fslab.org/Deedle/) data frame. As this is not possible here, we will do some ugly formatting.\n\n## Data Formatting/Parsing\n*)\n\nopen System\nopen System.Text.RegularExpressions\n\n/// Tuple of 4 data arrays representing the measured temperature for over a year.\nlet processedData = \n    // First separate the huge string in lines\n    rawData.Split([|\u0027\\n\u0027|], StringSplitOptions.RemoveEmptyEntries)\n    // Skip the first 5 rows until the real data starts, also skip the last row (length-2) to remove a \u0022\u003C/pre\u003E\u0022 at the end\n    |\u003E fun arr -\u003E arr.[5..arr.Length-2]\n    |\u003E Array.map (fun data -\u003E \n        // Regex pattern that will match groups of whitespace\n        let whitespacePattern = @\u0022\\s\u002B\u0022\n        // This is needed to tell regex to replace hits with a tabulator\n        let matchEval = MatchEvaluator(fun _ -\u003E @\u0022\\t\u0022 )\n        // The original data columns are separated by different amounts of whitespace.\n        // Therefore, we need a flexible string parsing option to replace any amount of whitespace with a single tabulator.\n        // This is done with the regex pattern above and the fsharp core library \u0022System.Text.RegularExpressions\u0022 \n        let tabSeparated = Regex.Replace(data, whitespacePattern, matchEval)\n        tabSeparated\n        // Split each row by tabulator will return rows with an equal amount of values, which we can access.\n        |\u003E fun dataStr -\u003E dataStr.Split([|@\u0022\\t\u0022|], StringSplitOptions.RemoveEmptyEntries)\n        |\u003E fun dataArr -\u003E \n            // Second value is the date of measurement, which we will parse to the DateTime type\n            DateTime.ParseExact(dataArr.[1], \u0022yyyyMMdd\u0022, Globalization.CultureInfo.InvariantCulture),\n            // 5th value is minimal temperature at that date.\n            float dataArr.[4],\n            // 6th value is average temperature over 24 timepoints at that date.\n            float dataArr.[5],\n            // 7th value is maximal temperature at that date.\n            float dataArr.[6]\n    )\n    // Sort by date\n    |\u003E Array.sortBy (fun (day,tn,tm,tx) -\u003E day)\n    // Unzip the array of value tuples, to make the different values easier accessible\n    |\u003E fun arr -\u003E \n        arr |\u003E Array.map (fun (day,tn,tm,tx) -\u003E day.ToShortDateString()),\n        arr |\u003E Array.map (fun (day,tn,tm,tx) -\u003E tm),\n        arr |\u003E Array.map (fun (day,tn,tm,tx) -\u003E tx),\n        arr |\u003E Array.map (fun (day,tn,tm,tx) -\u003E tn)\n\n(*** include-value:processedData ***)\n\n(**\n## Exploring the data set with Plotly.NET\n\nNext we create a create chart function with [Plotly.NET](https://plotly.net) to produce a visual representation of our data set.\n*)\n\nopen Plotly.NET\n\n// Because our data set is already rather wide we want to move the legend from the right side of the plot\n// to the right center. As this function is not defined for fsharp we will use the underlying js bindings (https://plotly.com/javascript/legend/#positioning-the-legend-inside-the-plot).\n// Declarative style in F# using underlying DynamicObj\n// https://plotly.net/#Declarative-style-in-F-using-the-underlying\nlet legend = \n    let tmp = Legend()\n    tmp?yanchor \u003C- \u0022top\u0022\n    tmp?y \u003C- 0.99\n    tmp?xanchor \u003C- \u0022left\u0022\n    tmp?x \u003C- 0.5\n    tmp\n\n/// This function will take \u0027processedData\u0027 as input and return a range chart with a line for the average temperature\n/// and a different colored area for the range between minimal and maximal temperature at that date.\nlet createTempChart (days,tm,tmUpper,tmLower) =\n    Chart.Range(\n        // data arrays\n        days, tm, tmUpper, tmLower,\n        StyleParam.Mode.Lines_Markers,\n        Color=\u0022#3D1244\u0022,\n        RangeColor=\u0022#F99BDE\u0022,\n        // Name for line in legend\n        Name=\u0022Average temperature over 24 timepoints each day\u0022,\n        // Name for lower point when hovering over chart\n        LowerName=\u0022Min temp\u0022,\n        // Name for upper point when hovering over chart\n        UpperName=\u0022Max temp\u0022\n    )\n    // Configure the chart with the legend from above\n    |\u003E Chart.withLegend legend\n    // Add name to y axis\n    |\u003E Chart.withY_AxisStyle(\u0022daily temperature [\u00B0C]\u0022)\n    |\u003E Chart.withSize (1000.,600.)\n\n/// Chart for original data set \nlet rawChart =\n    processedData \n    |\u003E createTempChart\n\n(**\u003Ccenter\u003E*)\n(***hide***)\nrawChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n(**\u003C/center\u003E*)\n\n(**\n\nAs you can see the data looks chaotic and is difficult to analyze. Trends are hidden in daily \ntemperature fluctuations and correlating events with temperature can get difficult. So next we want to\nsmooth the data to clearly see temperature trends.\n\n## Savitzky-Golay filter\n\nWe will use the \u0060Signal.Filtering.savitzkyGolay\u0060 function from [FSharp.Stats](https://fslab.org/FSharp.Stats/).\n\nParameters:\n\n- windowSize (\u0060int\u0060) the length of the window. Must be an odd integer number.\n- order (\u0060int\u0060) the order of the polynomial used in the filtering. Must be less then \u0060windowSize\u0060 - 1.\n- deriv (\u0060int\u0060) the order of the derivative to compute (default = 0 means only smoothing)\n- rate (\u0060int\u0060) this factor will influence amplitude when using Savitzky-Golay for derivation\n- data (\u0060float array\u0060) the values of the time history of the signal.\n\n*)\n\nopen FSharp.Stats\n\nlet smootheTemp ws order (days,tm,tmUpper,tmLower) =\n    let tm\u0027 = Signal.Filtering.savitzkyGolay ws order 0 1 tm\n    let tmUpper\u0027 = Signal.Filtering.savitzkyGolay ws order 0 1 tmUpper\n    let tmLower\u0027 = Signal.Filtering.savitzkyGolay ws order 0 1 tmLower\n    days,tm\u0027,tmUpper\u0027,tmLower\u0027\n\nlet smoothedChart =\n    processedData\n    |\u003E smootheTemp 31 4\n    |\u003E createTempChart \n\n(**\u003Ccenter\u003E*)\n(***hide***)\nsmoothedChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n(**\u003C/center\u003E*)"},{"uri":"https://fslab.org/004_clustering_DBSCAN.html","title":"Clustering with FSharp.Stats III: DBSCAN\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: Clustering with FSharp.Stats III: DBSCAN\ncategory: datascience\nauthors: Benedikt Venn\nindex: 2\n---\n*)\n\n(***condition:prepare***)\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n#r \u0022nuget: Newtonsoft.JSON\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.6\u0022\n#r \u0022nuget: FSharp.Data\u0022\n\n(***condition:ipynb***)\n#if IPYNB\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n#r \u0022nuget: Newtonsoft.JSON\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.6\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.6\u0022\n#r \u0022nuget: FSharp.Data\u0022\n#endif // IPYNB\n\n(**\n\n[![Binder]({{root}}images/badge-binder.svg)](https://mybinder.org/v2/gh/fslaborg/fslaborg.github.io/gh-pages?filepath={{fsdocs-source-basename}}.ipynb)\u0026emsp;\n[![Script]({{root}}images/badge-script.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.fsx)\u0026emsp;\n[![Notebook]({{root}}images/badge-notebook.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.ipynb)\n\n\n# Clustering with FSharp.Stats III: DBSCAN\n\n_Summary:_ This tutorial demonstrates DBSCAN with FSharp.Stats and how to visualize the results with Plotly.NET.\n\nIn the previous article of this series [hierarchical clustering using FSharp.Stats](https://fslab.org/content/tutorials/003_clustering_hierarchical.html) was introduced.\n\n## Introduction\n\nClustering methods can be used to group elements of a huge data set based on their similarity. Elements sharing similar properties cluster together and can be reported as coherent group.\nDensity-Based Spatial Clustering of Applications with Noise (DBSCAN) was developed to identify clusters with similar density and allows the exclusion of noise points.\n\n### Two global parameters have to be defined:\n\n  - **\u03B5 (eps)**: radius in which the neighbourhood of each point is checked \n  - **minPts**: minimal number of data points, that must fall into the neighbourhood of a region to be defined as dense\n\n### Data points are classified as:\n\n  - **Core point**: Within a radius of eps there are more (or equal) data points than minPts present.\n  - **Border point**: Within a radius of eps there are less data points than minPts present, but a core point is within the neighbourhood.\n  - **Noise point**: None of the conditions above apply.\n\n\u003Ccenter\u003E\n\u003Cimg style=\u0022max-width:75%\u0022 src=\u0022../../images/dbscan.png\u0022 class=\u0022center\u0022\u003E\u003C/img\u003E\n\u003C/center\u003E\n\n\u003Cbr\u003E\n\nFor demonstration of DBSCAN, the classic iris data set is used, which consists of 150 records, each of which contains four measurements and a species identifier.\nIn this tutorial we are going to perform DBSCAN on two- and three-dimensional data.\n\n## Referencing packages\n\n\u0060\u0060\u0060fsharp\n// Packages hosted by the Fslab community\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n// third party .net packages \n#r \u0022nuget: Plotly.NET, 2.0.0-preview.6\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.6\u0022\n#r \u0022nuget: FSharp.Data\u0022\n\u0060\u0060\u0060\n\n*)\n\n(**\n## Loading data\n*)\nopen FSharp.Data\nopen FSharp.Stats\nopen Deedle\n\n// Retrieve data using the FSharp.Data package and read it as dataframe using the Deedle package\nlet rawData = Http.RequestString @\u0022https://raw.githubusercontent.com/fslaborg/datasets/main/data/iris.csv\u0022\nlet df = Frame.ReadCsvString(rawData)\n\ndf.Print()\n\n\n(*** include-output ***)\n\n(**\n\nLet\u0027s take a first look at the data with 2D and 3D scatter plots using Plotly.NET. Each of the 150 records consists of four measurements and a species identifier. \nSince the species identifier occur several times (Iris-virginica, Iris-versicolor, and Iris-setosa), we create unique labels by adding the rows index to the species identifier.\n\n*)\nopen Plotly.NET\nopen FSharp.Stats.ML.Unsupervised\n\nlet header2D = [\u0022petal_length\u0022;\u0022petal_width\u0022]\nlet header3D = [\u0022sepal_length\u0022;\u0022petal_length\u0022;\u0022petal_width\u0022]\n\n//extract petal length and petal width\nlet data2D = \n    Frame.sliceCols header2D df\n    |\u003E Frame.toJaggedArray\n\n//extract sepal length, petal length, and petal width\nlet data3D = \n    Frame.sliceCols header3D df\n    |\u003E Frame.toJaggedArray\n\nlet labels = \n    Frame.getCol \u0022species\u0022 df\n    |\u003E Series.values\n    |\u003E Seq.mapi (fun i s -\u003E sprintf \u0022%s_%i\u0022 s i)\n\nlet rawChart2D =\n    let unzippedData =\n        data2D\n        |\u003E Array.map (fun x -\u003E x.[0],x.[1])\n    Chart.Scatter(unzippedData,mode=StyleParam.Mode.Markers,Labels=labels)\n    |\u003E Chart.withX_AxisStyle header2D.[0]\n    |\u003E Chart.withY_AxisStyle header2D.[1]\n    |\u003E Chart.withTitle \u0022rawChart2D\u0022\n\nlet rawChart3D =\n    let unzippedData =\n        data3D\n        |\u003E Array.map (fun x -\u003E x.[0],x.[1],x.[2])\n    Chart.Scatter3d(unzippedData,mode=StyleParam.Mode.Markers,Labels=labels)\n    |\u003E Chart.withX_AxisStyle header3D.[0]\n    |\u003E Chart.withY_AxisStyle header3D.[1]\n    |\u003E Chart.withZ_AxisStyle header3D.[2]\n    |\u003E Chart.withTitle \u0022rawChart3D\u0022\n\n(**\n\u003Ccenter\u003E\n*)\n(*** condition: ipynb ***)\n#if IPYNB\nrawChart2D\n#endif // IPYNB\n\n(***hide***)\nrawChart2D |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\u003Cbr\u003E\n*)\n\n(*** condition: ipynb ***)\n#if IPYNB\nrawChart3D\n#endif // IPYNB\n\n(***hide***)\nrawChart3D |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n\n(**\n\u003C/center\u003E\n## Clustering\n\nThe function that performs DBSCAN can be found at \u0060FSharp.Stats.ML.Unsupervised.DbScan.compute\u0060. It requires four input parameters:\n\n  1. Distance measure (\u0060from FSharp.Stats.ML.DistanceMetrics\u0060) (\u0060seq\u003C\u0027T\u003E -\u003E seq\u003C\u0027T\u003E -\u003E float\u0060)\n  1. minPts (\u0060int\u0060)\n  3. eps (\u0060float\u0060)\n  4. data points as sequence of coordinate sequences (\u0060seq\u003C#seq\u003C\u0027T\u003E\u003E\u0060)\n\nThe clustering result consists of a sequence of noise point coordinates and a sequence of clusters containing all related point coordinates.\n\n*)\nopen FSharp.Stats.ML\nopen FSharp.Stats.ML.Unsupervised\n\n\nlet eps2D = 0.5\nlet eps3D = 0.7\n\nlet minPts = 20\n\nlet result2D = DbScan.compute DistanceMetrics.Array.euclidean minPts eps2D data2D\n\n(***hide***)\nlet printClusters2D = result2D.ToString()\n(*** include-value:printClusters2D ***)\n\nlet result3D = DbScan.compute DistanceMetrics.Array.euclidean minPts eps3D data3D\n\n(***hide***)\nlet printClusters3D = result3D.ToString()\n\n(*** include-value:printClusters3D ***)\n\n(**\n## Visualization of clustering result\n\nTo visualize the clustering result coordinates of each cluster and noise points are visualized separately and combined in a single scatter plot.\n\n### 2D clustering result visualization\n\n*)\n\n\n//to create a chart with two dimensional data use the following function\n    \nlet chartCluster2D = \n    result2D.Clusterlist\n    |\u003E Seq.mapi (fun i l -\u003E\n        l\n        |\u003E Seq.map (fun x -\u003E x.[0],x.[1])\n        |\u003E Seq.distinct //more efficient visualization; no difference in plot but in point numbers\n        |\u003E Chart.Point\n        |\u003E Chart.withTraceName (sprintf \u0022Cluster %i\u0022 i))\n    |\u003E Chart.Combine\n\nlet chartNoise2D = \n    result2D.Noisepoints\n    |\u003E Seq.map (fun x -\u003E x.[0],x.[1])  \n    |\u003E Seq.distinct //more efficient visualization; no difference in plot but in point numbers\n    |\u003E Chart.Point\n    |\u003E Chart.withTraceName \u0022Noise\u0022\n\nlet chartTitle2D = \n    let noiseCount   = result2D.Noisepoints |\u003E Seq.length\n    let clusterCount = result2D.Clusterlist |\u003E Seq.length\n    let clPtsCount   = result2D.Clusterlist |\u003E Seq.sumBy Seq.length\n    $\u0022eps: %.1f{eps2D} minPts: %i{minPts} pts: %i{noiseCount \u002B clPtsCount} cluster: %i{clusterCount} noisePts: %i{noiseCount}\u0022 \n\nlet chart2D =\n    [chartNoise2D;chartCluster2D]\n    |\u003E Chart.Combine\n    |\u003E Chart.withTitle chartTitle2D\n    |\u003E Chart.withX_AxisStyle header2D.[0]\n    |\u003E Chart.withY_AxisStyle header2D.[1]\n(**\n\u003Ccenter\u003E\n*)\n(*** condition: ipynb ***)\n#if IPYNB\nchart2D\n#endif // IPYNB\n\n(***hide***)\nchart2D |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\u003C/center\u003E\n\n\n### 3D clustering result visualization\n\n\n\n*)\n\n\nlet chartCluster3D = \n    result3D.Clusterlist\n    |\u003E Seq.mapi (fun i l -\u003E\n        l\n        |\u003E Seq.map (fun x -\u003E x.[0],x.[1],x.[2])\n        |\u003E Seq.distinct //faster visualization; no difference in plot but in point number\n        |\u003E fun x -\u003E Chart.Scatter3d (x,StyleParam.Mode.Markers)\n        |\u003E Chart.withTraceName (sprintf \u0022Cluster_%i\u0022 i))\n    |\u003E Chart.Combine\n\nlet chartNoise3D =\n    result3D.Noisepoints\n    |\u003E Seq.map (fun x -\u003E x.[0],x.[1],x.[2])  \n    |\u003E Seq.distinct //faster visualization; no difference in plot but in point number\n    |\u003E fun x -\u003E Chart.Scatter3d (x,StyleParam.Mode.Markers)\n    |\u003E Chart.withTraceName \u0022Noise\u0022\n\nlet chartname3D = \n    let noiseCount   = result3D.Noisepoints |\u003E Seq.length\n    let clusterCount = result3D.Clusterlist |\u003E Seq.length\n    let clPtsCount   = result3D.Clusterlist |\u003E Seq.sumBy Seq.length\n    $\u0022eps: %.1f{eps3D} minPts: %i{minPts} pts: %i{noiseCount \u002B clPtsCount} cluster: %i{clusterCount} noisePts: %i{noiseCount}\u0022 \n   \nlet chart3D = \n    [chartNoise3D;chartCluster3D]\n    |\u003E Chart.Combine\n    |\u003E Chart.withTitle chartname3D\n    |\u003E Chart.withX_AxisStyle header3D.[0]\n    |\u003E Chart.withY_AxisStyle header3D.[1]\n    |\u003E Chart.withZ_AxisStyle header3D.[2]\n    \n//for faster computation you can use the squaredEuclidean distance and set your eps to its square\nlet clusteredChart3D() = DbScan.compute DistanceMetrics.Array.euclideanNaNSquared 20 (0.7**2.) data3D \n(**\n\u003Ccenter\u003E\n*)\n(*** condition: ipynb ***)\n#if IPYNB\nchart3D\n#endif // IPYNB\n\n(***hide***)\nchart3D |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\u003C/center\u003E\n\n## Limitations\n\n  1. The selection of minPts and eps is critical and even small deviations can severely influence the final results\n  2. When data points are of varying density, DBSCAN is not appropriate\n\n## Notes\n\n  - Please note that depending on what data you want to cluster, a column wise z-score normalization may be required. In the presented example differences in sepal width have a reduced influence because\n  the absolute variation is low.\n\n## References\n\n  - FSharp.Stats documentation, fslaborg, https://fslab.org/FSharp.Stats/Clustering.html\n  - Shinde and Sankhe, Comparison of Enhanced DBSCAN Algorithms: A Review, International Journal of Engeneering Research \u0026 Technology, 2017\n  - Nagaraju et al., An effective density based approach to detect complex data clusters using notion of neighborhood difference, Int. J. Autom. Comput., 2017, https://doi.org/10.1007/s11633-016-1038-7 \n\n*)\n\n"},{"uri":"https://fslab.org/005_testing_t-test.html","title":"Testing with FSharp.Stats I: t-test\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: Testing with FSharp.Stats I: t-test\ncategory: datascience\nauthors: Oliver Maus\nindex: 5\n---\n*)\n\n\n(***condition:prepare***)\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n#r \u0022nuget: Newtonsoft.JSON\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.6\u0022\n#r \u0022nuget: FSharp.Data\u0022\n\n(***condition:ipynb***)\n#if IPYNB\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n#r \u0022nuget: Newtonsoft.JSON\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.6\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.6\u0022\n#r \u0022nuget: FSharp.Data\u0022\n#endif // IPYNB\n\n\n(**\n\n[![Binder]({{root}}images/badge-binder.svg)](https://mybinder.org/v2/gh/fslaborg/fslaborg.github.io/gh-pages?filepath={{fsdocs-source-basename}}.ipynb)\u0026emsp;\n[![Script]({{root}}images/badge-script.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.fsx)\u0026emsp;\n[![Notebook]({{root}}images/badge-notebook.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.ipynb)\n\n# Testing with FSharp.Stats I: t-test\n\n## Getting started: The t-test\n\n_I love statistical testing_ - A sentence math teachers don\u0027t hear often during their time at school. In this tutorial we aim to give you a short introduction of the theory and how to \nperform the most used statistical test: the t-test\n\nSuppose you have measured the length of some leaves of two trees and you want to find out if the average length of the leaves is the same or if they differ from each other. \nIf you knew the population distributions of all leaves hanging on both trees the task would be easy, but since we only have samples from both populations, we have to apply a statistical test.\nStudent\u0027s t-test can be applied to test whether two samples have the same mean (H0), or if the means are different (H1). There are two requirements to the samples that have to be fulfilled:\n\n1. The variances of both samples have to be equal.\n\n2. The samples have to follow a normal distribution.\n\n_Note: Slight deviations from these requirements can be accepted but strong violations result in an inflated false positive rate. If the variances are not equal a Welch test can be performed._\n_There are some tests out there to check if the variances are equal or if the sample follows a normal distribution, but their effectiveness is discussed._\n_You always should consider the shape of the theoretical background distribution, instead of relying on preliminary tests rashly._\n\n\nThe t-test is one of the most used statistical tests in datascience. It is used to compare two samples in terms of statistical significance. \nOften a significance threshold (or \u0026alpha; level) of 0.05 is chosen to define if a p value is defined as statistically significant. A p value describes how likely it is to observe an effect\nat least as extreme as you observed (in the comparison) by chance. Low p values indicate a high confidence to state that there is a real difference and the observed difference is not caused by chance.\n\n*)\n\n#r \u0022nuget: FSharp.Data\u0022\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats, 0.4.2\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.6\u0022\n\nopen FSharp.Data\nopen Deedle\nopen Plotly.NET\n\n(**\n\nFor our purposes, we will use the housefly wing length dataset (from _Sokal et al., 1955, A morphometric analysis of DDT-resistant and non-resistant housefly strains_).\nHead over to the [Getting started](https://fslab.org/content/tutorials/4_getting-started.html#Data-access) tutorial where it is shown how to import datasets in a simple way.\n\n\n*)\n\n// We retrieve the dataset via FSharp.Data:\nlet rawDataHousefly = Http.RequestString @\u0022https://raw.githubusercontent.com/fslaborg/datasets/main/data/HouseflyWingLength.txt\u0022\n\nlet dataHousefly : seq\u003Cfloat\u003E = \n    Frame.ReadCsvString(rawDataHousefly, false, schema = \u0022wing length (mm * 10^1)\u0022)\n    |\u003E Frame.getCol \u0022wing length (mm * 10^1)\u0022\n    |\u003E Series.values\n    // We convert the values to mm\n    |\u003E Seq.map (fun x -\u003E x / 10.)\n\n(**\n\nLet us first have a look at the sample data with help of a boxplot. As shown below, the average wingspan is around 4.5 with variability ranges between 3.5 and 5.5.\n\n\u003Ccenter\u003E\n*)\n\nlet boxPlot = \n    Chart.BoxPlot(y = dataHousefly, Name = \u0022housefly\u0022, Boxpoints = StyleParam.Boxpoints.All, Jitter = 0.2)\n    |\u003E Chart.withY_AxisStyle \u0022wing length [mm]\u0022\n\n(*** condition: ipynb ***)\n#if IPYNB\nboxPlot\n#endif // IPYNB\n\n(***hide***)\nboxPlot |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\u003C/center\u003E\n\n## One-sample t-test\n\nWe want to analyze if an estimated expected value differs from the sample above. Therefore, we perform a one-sample t-test which covers exactly this situation.\n\n\u003Ccenter\u003E\n\u003Cimg style=\u0022max-width:75%\u0022 src=\u0022../../images/OneSampleTTest.png\u0022\u003E\u003C/img\u003E\n\u003C/center\u003E\nFig. 1: _The one-sample t-test._ The dashed orange line depicts the distribution of our sample, the green bar the expected value to test against.\n\n*)\n\nopen FSharp.Stats\nopen FSharp.Stats.Testing\n\n// The testing module in FSharp.Stats require vectors as input types, thus we transform our array into a vector:\nlet vectorDataHousefly = vector dataHousefly\n\n// The expected value of our population.\nlet expectedValue = 4.5\n\n// Perform the one-sample t-test with our vectorized data and our exptected value as parameters.\nlet oneSampleResult = TTest.oneSample vectorDataHousefly expectedValue\n\n(*** hide ***)\n\n(*** include-value:oneSampleResult ***)\n\n(**\n\nThe function returns a \u0060TTestStatistics\u0060 type. If contains the fields \n  - \u0060Statistic\u0060: defines the exact teststatistic\n  - \u0060DegreesOfFreedom\u0060: defines the degrees of freedom\n  - \u0060PValueLeft\u0060: the left-tailed p-value \n  - \u0060PValueRight\u0060: the right-tailed p-value\n  - \u0060PValue\u0060: the two-tailed p-value\n\nAs we can see, when looking at the two-tailed p-value, our sample does _not_ differ significantly from our expected value. This matches our visual impression of the boxplot, where the sample distribution \nis centered around 4.5.\n\n\n## Two-sample t-test (unpaired data)\n\nThe t-test is most often used in its two-sample variant. Here, two samples, independent from each other, are compared. It is required that both samples are normally distributed.\nIn this next example, we are going to see if the gender of college athletes determines the number of concussions suffered over 3 years (from: _Covassin et al., 2003, Sex Differences and the Incidence of Concussions Among Collegiate Athletes, Journal of Athletic Training_).\n\n\u003Ccenter\u003E\n\u003Cimg style=\u0022max-width:75%\u0022 src=\u0022../../images/TwoSampleTTest.png\u0022\u003E\u003C/img\u003E\n\u003C/center\u003E\nFig. 2: _The two-sample t-test._ The dashed orange and green lines depict the distribution of both samples that are compared with each other.\n\n*)\n\nopen System.Text\n\nlet rawDataAthletes = Http.RequestString @\u0022https://raw.githubusercontent.com/fslaborg/datasets/main/data/ConcussionsInMaleAndFemaleCollegeAthletes_adapted.tsv\u0022\n\nlet dataAthletesAsStream = new System.IO.MemoryStream(rawDataAthletes |\u003E Encoding.UTF8.GetBytes)\n\n// The schema helps us setting column keys.\nlet dataAthletesAsFrame = Frame.ReadCsv(dataAthletesAsStream, hasHeaders = false, separators = \u0022\\t\u0022, schema = \u0022Gender, Sports, Year, Concussion, Count\u0022)\n\ndataAthletesAsFrame.Print()\n\n// We need to filter out the columns and rows we don\u0027t need. Thus, we filter out the rows where the athletes suffered no concussions  \n// as well as filter out the columns without the number of concussions.\nlet dataAthletesFemale, dataAthletesMale =\n    let getAthleteGenderData gender =\n        let dataAthletesOnlyConcussion =\n            dataAthletesAsFrame\n            |\u003E Frame.filterRows (fun r objS -\u003E objS.GetAs \u0022Concussion\u0022)\n        let dataAthletesGenderFrame =\n            dataAthletesOnlyConcussion\n            |\u003E Frame.filterRows (fun r objS -\u003E objS.GetAs \u0022Gender\u0022 = gender)\n        dataAthletesGenderFrame\n        |\u003E Frame.getCol \u0022Count\u0022 \n        |\u003E Series.values\n        |\u003E vector\n    getAthleteGenderData \u0022Female\u0022, getAthleteGenderData \u0022Male\u0022\n    \n(**\n\nAgain, let\u0027s check our data via boxplots before we proceed on comparing them.\n\n*)\n\nlet boxPlot2 = \n    [\n        Chart.BoxPlot(y = dataAthletesFemale, Name = \u0022female college athletes\u0022, Boxpoints = StyleParam.Boxpoints.All, Jitter = 0.2)\n        Chart.BoxPlot(y = dataAthletesMale, Name = \u0022male college athletes\u0022, Boxpoints = StyleParam.Boxpoints.All, Jitter = 0.2)\n    ]\n    |\u003E Chart.Combine\n    |\u003E Chart.withY_AxisStyle \u0022number of concussions over 3 years\u0022\n\n(**\n\n\u003Ccenter\u003E\n\n*)\n\n(*** condition: ipynb ***)\n#if IPYNB\nboxPlot2\n#endif // IPYNB\n\n(***hide***)\nboxPlot2 |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\u003C/center\u003E\n\nBoth samples are tested against using \u0060FSharp.Stats.Testing.TTest.twoSample\u0060 and assuming equal variances.\n\n*)\n\n// We test both samples against each other, assuming equal variances.\nlet twoSampleResult = TTest.twoSample true dataAthletesFemale dataAthletesMale\n\n(*** include-value:twoSampleResult ***)\n\n(**\n\nWith a p value of 0.58 the t-test indicate that there\u0027s no significant difference between the number of concussions over 3 years between male and female college athletes.\n\n\n## Two-sample t-test (paired data)\n\nPaired data describes data where each value from the one sample is connected with its respective value from the other sample.  \nIn the next case, the endurance performance of several persons in a normal situation (control situation) is compared to their performance after ingesting a specific amount of caffeine*. \nIt is the same person that performs the exercise but under different conditions. Thus, the resulting values of the persons under each condition are compared.  \nAnother example are time-dependent experiments: One measures, e.g., the condition of cells stressed with a high surrounding temperature in the beginning and after 30 minutes. \nThe measured cells are always the same, yet their conditions might differ.\nDue to the connectivity of the sample pairs the samples must be of equal length.\n\n*Source: W.J. Pasman, M.A. van Baak, A.E. Jeukendrup, A. de Haan (1995). _The Effect of Different Dosages of Caffeine on Endurance Performance Time_, International Journal of Sports Medicine, Vol. 16, pp225-230.\n\n*)\n\nlet rawDataCaffeine = Http.RequestString @\u0022https://raw.githubusercontent.com/fslaborg/datasets/main/data/CaffeineAndEndurance(wide)_adapted.tsv\u0022\n\nlet dataCaffeineAsStream = new System.IO.MemoryStream(rawDataCaffeine |\u003E Encoding.UTF8.GetBytes)\nlet dataCaffeineAsFrame = Frame.ReadCsv(dataCaffeineAsStream, hasHeaders = false, separators = \u0022\\t\u0022, schema = \u0022Subject ID, no Dose, 5 mg, 9 mg, 13 mg\u0022)\n\n// We want to compare the subjects\u0027 performances under the influence of 13 mg caffeine and in the control situation.\nlet dataCaffeineNoDose, dataCaffeine13mg =\n    let getVectorFromCol col = \n        dataCaffeineAsFrame\n        |\u003E Frame.getCol col\n        |\u003E Series.values\n        |\u003E vector\n    getVectorFromCol \u0022no Dose\u0022, getVectorFromCol \u002213 mg\u0022\n\n// Transforming our data into a chart.\nlet visualizePairedData = \n    Seq.zip dataCaffeineNoDose dataCaffeine13mg\n    |\u003E Seq.mapi (fun i (control,treatment) -\u003E \n        let participant = \u0022Person \u0022 \u002B string i \n        Chart.Line([\u0022no dose\u0022, control; \u002213 mg\u0022, treatment], Name = participant)\n        )\n    |\u003E Chart.Combine\n    |\u003E Chart.withX_AxisStyle \u0022\u0022\n    |\u003E Chart.withY_AxisStyle(\u0022endurance performance\u0022, MinMax = (0.,100.))\n\n(**\n\n\u003Ccenter\u003E\n\n*)\n\n(*** condition: ipynb ***)\n#if IPYNB\nvisualizePairedData\n#endif // IPYNB\n\n(***hide***)\nvisualizePairedData |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\n\u003C/center\u003E\n\nThe function for pairwise t-tests can be found at \u0060FSharp.Stats.Testing.TTest.twoSamplePaired\u0060. Note, that the order of the elements in each vector must be the same, so that a pairwise comparison can be performed.\n\n*)\n\nlet twoSamplePairedResult = TTest.twoSamplePaired dataCaffeineNoDose dataCaffeine13mg\n\n(*** include-value:twoSamplePairedResult ***)\n\n(**\n\nThe two-sample paired t-test suggests a significant difference beween caffeine and non-caffeine treatment groups with a p-value of 0.012. \n\n*)"},{"uri":"https://fslab.org/introductionII.html","title":"F# Introduction II: Scripting in F#\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: F# Introduction II: Scripting in F#\ncategory: fsharp\nauthors: Jonathan Ott\nindex: 2\n---\n*)\n(**\n# F# Introduction II: Scripting in F#\n\n## Creating a .fsx file\n\n### Visual Studio\n\n* Open Visual Studio and navigate to the \u0022File\u0022 tab, where you select to create a new file.\n* Select the \u0022F# Script File\u0022 option.  \n    \n    ![]({{root}}images/FsxVS.png)\n\n* You now have a working script file. You can write code and execute it by selecting it and pressing \u0060Alt \u002B Enter\u0060.\n\n### Visual Studio Code\n\n* Open Visual Studio Code and navigate to the \u0022File\u0022 tab, where you select to create a new file.\n* You will then be prompted to select a language. Choose F# there.  \n\n    ![]({{root}}images/FsxVSCode.png)\n\n* You now have a working script file. You can write code and execute it by selecting it and pressing \u0060Alt \u002B Enter\u0060.\n* When you are done with your file save it as .fsx.\n\n## Referencing packages\n\n* Packages on nuget can be referenced using \u0027#r \u0022nuget: PackageName\u0022\u0027:\n*)\n// References the latest stable package\n#r \u0022nuget: FSharp.Stats\u0022\n// References a sepcific package version\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.6\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.6\u0022\n(**\n* Alternatively, .dll files can be referenced directly with the following syntax:\n*)\n(***do-not-eval***)\n#r @\u0022Your\\Path\\To\\Package\\PackageName.dll\u0022\n\n(**\n## Working with notebooks\n\n* Visual Studio Code supports working with notebooks\n* To work with notebooks, you need to install the [.NET Interactive Notebooks](https://marketplace.visualstudio.com/items?itemName=ms-dotnettools.dotnet-interactive-vscode) extension.  \n\n    ![]({{root}}images/NotebooksExt.png)\n\n* A new Notebook can be opened by pressing \u0060Ctrl \u002B Shift \u002B P\u0060 and selecting \u0022.NET Interactive: Create new blank notebook\u0022.\n* You will then be prompted to create it either as .dib or .ipynb.\n* When asked for the language, choose F#\n* Notebooks contain Text- and Codeblocks:\n* Adding a new Text- or Codeblock can be done by hovering at the upper or lower border of an existing block or upper part of the notebook and pressing \u0060\u002BCode\u0060 or \u0060\u002BMarkdown\u0060  \n\n    ![]({{root}}images/NBBlock.png)\n\n* Working with Textblocks:\n    You can edit a Textblock by doubleklicking on it. Inside a Textblock you can write plain text or style it with [Markdown](https://en.wikipedia.org/wiki/Markdown).\n    Once you are finished you can press the \u0060Esc\u0060 button.\n* Working with Codeblocks:\n    You can start editing any Codeblock by clicking in it. In there you can start writing your own code or edit existing code. Once you are done you can execute the Codeblock by pressing \u0060Ctrl \u002B Alt \u002B Enter\u0060.\n    If you want to execute all codeblocks at once, you can press on the two arrows in the upper left corner of the notebook.\n*)\n"},{"uri":"https://fslab.org/introductionI.html","title":"F# Introduction I: Setting up an environment\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: F# Introduction I: Setting up an environment\ncategory: fsharp\nauthors: Jonathan Ott\nindex: 1\n---\n*)\n(**\n# F# Introduction I: Setting up an environment\n\n## Installing Visual Studio Code\n\n* Download the recommended [.NET SDK](https://dotnet.microsoft.com/download) for your operating system and install it.\n    * By Selecting [All .NET downloads](https://dotnet.microsoft.com/download/dotnet) you can between installers for different operating systems.  \n\n    ![]({{root}}images/DotnetSDK.png)\n\n* Download the latest stable build of [Visual Studio Code](https://code.visualstudio.com/) for your operating system and install it.  \n\n    ![]({{root}}images/VSCode.png)\n\n* Open Visual Studio Code, navigate to the \u0022Extensions\u0022 tab and install \u0022Ionide-fsharp\u0022  \n\n    ![]({{root}}images/IonideVSCode.png)\n\n## Installing Visual Studio\n\n### Windows\n\n* Download the desired version of [Visual Studio](https://visualstudio.microsoft.com/downloads/?utm_medium=microsoft\u0026utm_source=docs.microsoft.com\u0026utm_campaign=inline\u002Blink\u0026utm_content=download\u002Bvs2019)  \n\n    ![]({{root}}images/VSWindows.png)\n\n* When executing the installer select \u0022.NET desktop development\u0022 under workloads and make sure \u0022F# desktop language support\u0022 is ticked as well on the right side.  \n\n    ![]({{root}}images/VSInstaller.png)\n\n* Select any other workloads or individual components you are interested in and start the installation.\n\n### macOS\n\n* Download Visual Studio for Mac [Visual Studio](https://visualstudio.microsoft.com/downloads/?utm_medium=microsoft\u0026utm_source=docs.microsoft.com\u0026utm_campaign=inline\u002Blink\u0026utm_content=download\u002Bvs2019)  \n\n    ![]({{root}}images/VSMac.png)\n\n* Run the Installer. F# is installed by default.\n*)"},{"uri":"https://fslab.org/introductionIII.html","title":"F# Introduction III: Library Setup\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: F# Introduction III: Library Setup\ncategory: fsharp\nauthors: Kevin Schneider, Jonathan Ott\nindex: 3\n---\n*)\n\n(***hide***)\n#r \u0022nuget: BlackFox.Fake.BuildTask\u0022\n#r \u0022nuget: Fake.Core.Target\u0022\n#r \u0022nuget: Fake.Core.Process\u0022\n#r \u0022nuget: Fake.Core.ReleaseNotes\u0022\n#r \u0022nuget: Fake.IO.FileSystem\u0022\n#r \u0022nuget: Fake.DotNet.Cli\u0022\n#r \u0022nuget: Fake.DotNet.MSBuild\u0022\n#r \u0022nuget: Fake.DotNet.AssemblyInfoFile\u0022\n#r \u0022nuget: Fake.DotNet.Paket\u0022\n#r \u0022nuget: Fake.DotNet.FSFormatting\u0022\n#r \u0022nuget: Fake.DotNet.Fsi\u0022\n#r \u0022nuget: Fake.DotNet.NuGet\u0022\n#r \u0022nuget: Fake.Api.Github\u0022\n#r \u0022nuget: Fake.DotNet.Testing.Expecto \u0022\n#r \u0022nuget: Fake.Tools.Git\u0022\n\n(**\n# F# Introduction III: Library Setup\n\nThis guide shows an example setup for a library. This is not the only way on how to do this, but merely a possibility. As always, this guide is meant as a starting point to be expanded upon. \nFor example, unit tests and full buildchains with automatic releases can be added to this template. \nThe installation of .NET 5.0 or dotnet SDK 3.1 LTS is required. It is also recommended to use [GitHub](https://github.com/) when following this example.\n\n## Initializing the repository\n\n* An easy way to initialize a repository is by creating a new one using GitHub and cloning it.\n    * You can automatically add a readme, a .gitignore with many entries for Visual Studio already added and a license of choice.\n\n    ![]({{root}}images/InitRepo.png)\n\n* After you cloned the initialized repository, it should look like this:  \n\n    ![]({{root}}images/Lib1.png)\n\n## Initializing the library\n\n* The stock library template is just fine (change framework if you know what you are doing):\n    \u0060dotnet new classlib -lang F# -n \u0022YourNameHere\u0022 --framework net5.0 -o src/YourNameHere\u0060\n* Add an entry for the \u0027pkg\u0027 folder to your \u0060.gitignore\u0060\n* Create a \u0060RELEASE_NOTES.md\u0060 file in the project root, make sure to add at least one version header like this:\n\n\u0060\u0060\u0060\n### 0.0.1 - 28/7/2021\n\u0060\u0060\u0060\n* Add a solution to your projekt with \u0060dotnet new sln --name YourNameHere\u0060\n* After you completed the previous steps your folder should look like this:  \n\n    ![]({{root}}images/Lib2.png)\n\n## Initializing the buildchain with FAKE\n\n* Initialize a local tool manifest that will keep track of the usable local dotnet tools in this project.\n    * In the project root: \u0060dotnet new tool-manifest\u0060\n* In the project root: Install the fake cli as local tool: \u0060dotnet tool install fake-cli\u0060\n* In the project root: Install paket as local tool: \u0060dotnet tool install paket\u0060\n* In the project root: Create a new empty \u0060build.fsx\u0060 file\n* Your folder should now look like this:  \n\n    ![]({{root}}images/Lib3.png)\n\n* Open the \u0060build.fsx\u0060 file (intellisense will not work right after creating it) and add the following content.\n\nFirst, lets reference the dependencies of the build script. In fake they are loaded via the \u0060paket\u0060 manager:\n\n\u0060\u0060\u0060fsharp\n#r \u0022paket:\nnuget BlackFox.Fake.BuildTask\nnuget Fake.Core.Target\nnuget Fake.Core.Process\nnuget Fake.Core.ReleaseNotes\nnuget Fake.IO.FileSystem\nnuget Fake.DotNet.Cli\nnuget Fake.DotNet.MSBuild\nnuget Fake.DotNet.AssemblyInfoFile\nnuget Fake.DotNet.Paket\nnuget Fake.DotNet.FSFormatting\nnuget Fake.DotNet.Fsi\nnuget Fake.DotNet.NuGet\nnuget Fake.Api.Github\nnuget Fake.DotNet.Testing.Expecto \nnuget Fake.Tools.Git //\u0022\n\u0060\u0060\u0060\n\nThen, we open the dependencies. Note that for getting intellisense, you will have to run the script once with the fake runner (see [here](#Running-the-build-script)).\n*)\n\n#if !FAKE\n#load \u0022./.fake/build.fsx/intellisense.fsx\u0022\n#r \u0022netstandard\u0022 // Temp fix for https://github.com/dotnet/fsharp/issues/5216\n#endif\n\nopen BlackFox.Fake\nopen System.IO\nopen Fake.Core\nopen Fake.DotNet\nopen Fake.IO\nopen Fake.IO.FileSystemOperators\nopen Fake.IO.Globbing.Operators\nopen Fake.Tools\n\n[\u003CAutoOpen\u003E]\n/// user interaction prompts for critical build tasks where you may want to interrupt when you see wrong inputs.\nmodule MessagePrompts =\n\n    let prompt (msg:string) =\n        System.Console.Write(msg)\n        System.Console.ReadLine().Trim()\n        |\u003E function | \u0022\u0022 -\u003E None | s -\u003E Some s\n        |\u003E Option.map (fun s -\u003E s.Replace (\u0022\\\u0022\u0022,\u0022\\\\\\\u0022\u0022))\n\n    let rec promptYesNo msg =\n        match prompt (sprintf \u0022%s [Yn]: \u0022 msg) with\n        | Some \u0022Y\u0022 | Some \u0022y\u0022 -\u003E true\n        | Some \u0022N\u0022 | Some \u0022n\u0022 -\u003E false\n        | _ -\u003E System.Console.WriteLine(\u0022Sorry, invalid answer\u0022); promptYesNo msg\n\n    let releaseMsg = \u0022\u0022\u0022This will stage all uncommitted changes, push them to the origin and bump the release version to the latest number in the RELEASE_NOTES.md file. \n        Do you want to continue?\u0022\u0022\u0022\n\n    let releaseDocsMsg = \u0022\u0022\u0022This will push the docs to gh-pages. Remember building the docs prior to this. Do you want to continue?\u0022\u0022\u0022\n\n/// Executes a dotnet command in the given working directory\nlet runDotNet cmd workingDir =\n    let result =\n        DotNet.exec (DotNet.Options.withWorkingDirectory workingDir) cmd \u0022\u0022\n    if result.ExitCode \u003C\u003E 0 then failwithf \u0022\u0027dotnet %s\u0027 failed in %s\u0022 cmd workingDir\n(**\nNote: This \u0060build.fsx\u0060 will be gradually epxanded\n\n* Add the \u0060ProjectInfo\u0060 module to the \u0060build.fsx\u0060 file, which will contain all relevant metadata for the buildchain except nuget package metadata (more on that later).\n* Replace all strings with the correct ones for your project.\n*)\n/// Metadata about the project\nmodule ProjectInfo = \n\n    let project = \u0022LibraryExample\u0022\n\n    let summary = \u0022An example Library\u0022\n\n    let configuration = \u0022Release\u0022\n\n    // Git configuration (used for publishing documentation in gh-pages branch)\n    // The profile where the project is posted\n    let gitOwner = \u0022YourGitProfile\u0022\n    let gitName = \u0022YourNameHere\u0022\n\n    let gitHome = sprintf \u0022%s/%s\u0022 \u0022https://github.com\u0022 gitOwner\n\n    let projectRepo = sprintf \u0022%s/%s/%s\u0022 \u0022https://github.com\u0022 gitOwner gitName\n\n    let website = \u0022/YourNameHere\u0022\n\n    let pkgDir = \u0022pkg\u0022\n\n    let release = ReleaseNotes.load \u0022RELEASE_NOTES.md\u0022\n\n    let stableVersion = SemVer.parse release.NugetVersion\n\n    let stableVersionTag = (sprintf \u0022%i.%i.%i\u0022 stableVersion.Major stableVersion.Minor stableVersion.Patch )\n\n    let mutable prereleaseSuffix = \u0022\u0022\n\n    let mutable prereleaseTag = \u0022\u0022\n\n    let mutable isPrerelease = false\n(**\n* Add the \u0060BasicTasks\u0060 module to the \u0060build.fsx\u0060 file, which will contain the minimal build chain.\n*)\n/// Barebones, minimal build tasks\nmodule BasicTasks = \n\n    open ProjectInfo\n\n    let setPrereleaseTag = BuildTask.create \u0022SetPrereleaseTag\u0022 [] {\n        printfn \u0022Please enter pre-release package suffix\u0022\n        let suffix = System.Console.ReadLine()\n        prereleaseSuffix \u003C- suffix\n        prereleaseTag \u003C- (sprintf \u0022%s-%s\u0022 release.NugetVersion suffix)\n        isPrerelease \u003C- true\n    }\n\n    let clean = BuildTask.create \u0022Clean\u0022 [] {\n        !! \u0022src/**/bin\u0022\n        \u002B\u002B \u0022src/**/obj\u0022\n        \u002B\u002B \u0022pkg\u0022\n        \u002B\u002B \u0022bin\u0022\n        |\u003E Shell.cleanDirs \n    }\n\n    let build = BuildTask.create \u0022Build\u0022 [clean] {\n        !! \u0022src/**/*.*proj\u0022\n        |\u003E Seq.iter (DotNet.build id)\n    }\n\n    let copyBinaries = BuildTask.create \u0022CopyBinaries\u0022 [clean; build] {\n        let targets = \n            !! \u0022src/**/*.??proj\u0022\n            -- \u0022src/**/*.shproj\u0022\n            |\u003E  Seq.map (fun f -\u003E ((Path.getDirectory f) \u003C/\u003E \u0022bin\u0022 \u003C/\u003E configuration, \u0022bin\u0022 \u003C/\u003E (Path.GetFileNameWithoutExtension f)))\n        for i in targets do printfn \u0022%A\u0022 i\n        targets\n        |\u003E  Seq.iter (fun (fromDir, toDir) -\u003E Shell.copyDir toDir fromDir (fun _ -\u003E true))\n    }\n(**\n* At the bottom of the \u0060build.fsx\u0060 file, add the following lines:\n*)\nopen BasicTasks\nBuildTask.runOrDefault copyBinaries\n(**\n* Create a \u0060build.cmd\u0060 or \u0060build.sh\u0060 file (or both) with the following lines:\n\n### build.cmd\n\n\u0060\u0060\u0060shell\ndotnet tool restore\ndotnet fake build %*\n\u0060\u0060\u0060\n\n### build.sh\n\n\u0060\u0060\u0060shell\n#!/usr/bin/env bash\n\nset -eu\nset -o pipefail\n\ndotnet tool restore\ndotnet fake build \u0022$@\u0022\n\u0060\u0060\u0060\n\n## Running the build script\n\n* You can now run your build via calling either \u0060build.cmd\u0060 or \u0060build.sh\u0060.\n    * Optionally, you can pass the \u0060-t\u0060 argument with it to execute a specific build task, e.g \u0060./build.cmd -t clean\u0060 to execute the clean target.\n    * The first time you run the build.cmd will also enable intellisense for the fake build script\n* After building for the first time your folder will look like this:  \n\n    ![]({{root}}images/Lib4.png)\n\n## Packing a nuget package\n\n* Add nuget package metadata to the project file (src/LibraryExample/LibraryExample.fsproj) and adapt accordingly:\n\n\u0060\u0060\u0060\n\u003CPropertyGroup\u003E\n    \u003CAuthors\u003EYourName\u003C/Authors\u003E\n    \u003CDescription\u003EYour description here\u003C/Description\u003E\n    \u003CSummary\u003EYour summary here\u003C/Summary\u003E\n    \u003CPackageLicenseExpression\u003EMIT\u003C/PackageLicenseExpression\u003E\n    \u003CPackageProjectUrl\u003Ehttps://fslab.org/projectName/\u003C/PackageProjectUrl\u003E\n    \u003CPackageIconUrl\u003Ehttps://fslab.org/projectName/img/logo.png\u003C/PackageIconUrl\u003E\n    \u003CPackageTags\u003Edocumentation fsharp csharp dotnet\u003C/PackageTags\u003E\n    \u003CRepositoryUrl\u003Ehttps://github.com/fslaborg/projectName\u003C/RepositoryUrl\u003E\n    \u003CRepositoryType\u003Egit\u003C/RepositoryType\u003E\n    \u003CFsDocsLicenseLink\u003Ehttps://github.com/fslaborg/projectName/blob/master/LICENSE\u003C/FsDocsLicenseLink\u003E\n    \u003CFsDocsReleaseNotesLink\u003Ehttps://github.com/fslaborg/projectName/blob/master/RELEASE_NOTES.md\u003C/FsDocsReleaseNotesLink\u003E\n\u003C/PropertyGroup\u003E\n\u0060\u0060\u0060\n\n* Add the \u0060PackageTasks\u0060 module to the \u0060build.fsx\u0060 file, which will take care of building nuget packages for both stable and prerelease packages:\n*)\n\n/// Package creation\nmodule PackageTasks = \n\n    open ProjectInfo\n\n    open BasicTasks\n\n    let pack = BuildTask.create \u0022Pack\u0022 [clean; build; copyBinaries] {\n        if promptYesNo (sprintf \u0022creating stable package with version %s OK?\u0022 stableVersionTag ) \n            then\n                !! \u0022src/**/*.*proj\u0022\n                |\u003E Seq.iter (Fake.DotNet.DotNet.pack (fun p -\u003E\n                    let msBuildParams =\n                        {p.MSBuildParams with \n                            Properties = ([\n                                \u0022Version\u0022,stableVersionTag\n                                \u0022PackageReleaseNotes\u0022,  (release.Notes |\u003E String.concat \u0022\\r\\n\u0022)\n                            ] @ p.MSBuildParams.Properties)\n                        }\n                    {\n                        p with \n                            MSBuildParams = msBuildParams\n                            OutputPath = Some pkgDir\n                    }\n                ))\n        else failwith \u0022aborted\u0022\n    }\n\n    let packPrerelease = BuildTask.create \u0022PackPrerelease\u0022 [setPrereleaseTag; clean; build; copyBinaries] {\n        if promptYesNo (sprintf \u0022package tag will be %s OK?\u0022 prereleaseTag )\n            then \n                !! \u0022src/**/*.*proj\u0022\n                //-- \u0022src/**/Plotly.NET.Interactive.fsproj\u0022\n                |\u003E Seq.iter (Fake.DotNet.DotNet.pack (fun p -\u003E\n                            let msBuildParams =\n                                {p.MSBuildParams with \n                                    Properties = ([\n                                        \u0022Version\u0022, prereleaseTag\n                                        \u0022PackageReleaseNotes\u0022,  (release.Notes |\u003E String.toLines )\n                                    ] @ p.MSBuildParams.Properties)\n                                }\n                            {\n                                p with \n                                    VersionSuffix = Some prereleaseSuffix\n                                    OutputPath = Some pkgDir\n                                    MSBuildParams = msBuildParams\n                            }\n                ))\n        else\n            failwith \u0022aborted\u0022\n    }\n(**\n* You can test both targets with \u0060./build.cmd -t Pack\u0060 or \u0060./build.cmd -t PackPrerelease\u0060 respectively.\n* The packages can be found in the \u0060pkg\u0060 folder in the project root. Since you do not want to host your nuget packages on github, do also remove this folder from source control by adding /pkg to your .gitignore file.\n* If you want users of your nuget package to have a pleasant debugging experience you can make use of [sourcelink](https://github.com/dotnet/sourcelink).\n    * To install this package, navigate to the folder of your project, e.g. src/LibraryExample and call: \u0060dotnet add package Microsoft.SourceLink.GitHub --version 1.0.0\u0060\n\n## Documentation\n\n* In the project root: Install fsdocs as local tool: \u0060dotnet tool install FSharp.Formatting.CommandTool\u0060\n* In the project root: Install the fslab documentation template: \u0060dotnet new -i FsLab.DocumentationTemplate::*\u0060\n* Initialize the fslab documentation template: \u0060dotnet new fslab-docs\u0060\n* Add the \u0060DocumentationTasks\u0060 module to the \u0060build.fsx\u0060 file, which will take care initializing documentation files and developing them:\n*)\n/// Build tasks for documentation setup and development\nmodule DocumentationTasks =\n\n    open ProjectInfo\n\n    open BasicTasks\n\n    let buildDocs = BuildTask.create \u0022BuildDocs\u0022 [build; copyBinaries] {\n        printfn \u0022building docs with stable version %s\u0022 stableVersionTag\n        runDotNet \n            (sprintf \u0022fsdocs build --eval --clean --property Configuration=Release --parameters fsdocs-package-version %s\u0022 stableVersionTag)\n            \u0022./\u0022\n    }\n\n    let buildDocsPrerelease = BuildTask.create \u0022BuildDocsPrerelease\u0022 [setPrereleaseTag; build; copyBinaries] {\n        printfn \u0022building docs with prerelease version %s\u0022 prereleaseTag\n        runDotNet \n            (sprintf \u0022fsdocs build --eval --clean --property Configuration=Release --parameters fsdocs-package-version %s\u0022 prereleaseTag)\n            \u0022./\u0022\n    }\n\n    let watchDocs = BuildTask.create \u0022WatchDocs\u0022 [build; copyBinaries] {\n        printfn \u0022watching docs with stable version %s\u0022 stableVersionTag\n        runDotNet \n            (sprintf \u0022fsdocs watch --eval --clean --property Configuration=Release --parameters fsdocs-package-version %s\u0022 stableVersionTag)\n            \u0022./\u0022\n    }\n\n    let watchDocsPrerelease = BuildTask.create \u0022WatchDocsPrerelease\u0022 [setPrereleaseTag; build; copyBinaries] {\n        printfn \u0022watching docs with prerelease version %s\u0022 prereleaseTag\n        runDotNet \n            (sprintf \u0022fsdocs watch --eval --clean --property Configuration=Release --parameters fsdocs-package-version %s\u0022 prereleaseTag)\n            \u0022./\u0022\n    }\n(**\n* To create a new documentation file, run \u0060./build.cmd -t InitDocsPage\u0060\n* Add \u0060tmp/\u0060 to \u0060.gitignore\u0060\n* To run fsdocs in watchmode (hot reaload local hosting of your docs for live development), run \u0060dotnet fsdocs watch\u0060\n* Your repository should now look like this:  \n\n    ![]({{root}}images/Lib5.png)\n\n## Adding nuget packages\n\n* Navigate to your project folder (i. e. \u0060src/LibraryExample\u0060)\n* If you want to specify a package source other than nuget.com (e.g. a local package) you can specify other sources after adding a nuget.config file to your project root:\n\n\u0060\u0060\u0060\n\u003C?xml version=\u00221.0\u0022 encoding=\u0022utf-8\u0022?\u003E\n\u003Cconfiguration\u003E\n\u003C/configuration\u003E\n\u0060\u0060\u0060\n\n* The following example would add the local lib folder as a new nuget source to your local nuget.config file: \u0060dotnet nuget add source ./lib --configfile nuget.config\u0060\n\n\u0060\u0060\u0060\n\u003C?xml version=\u00221.0\u0022 encoding=\u0022utf-8\u0022?\u003E\n\u003Cconfiguration\u003E\n  \u003CpackageSources\u003E\n    \u003Cadd key=\u0022Package source 1\u0022 value=\u0022./lib\u0022 /\u003E\n  \u003C/packageSources\u003E\n\u003C/configuration\u003E\n\u0060\u0060\u0060\n\n* Calling \u0060dotnet add package PackageName --version PackageVersion\u0060 will still start to search for the package on nuget.com, but if this call is unsuccesful, Package source 1 will be used as a fallback. For a more complete view on how to use nuget.config files please visit the [offical documentation](https://docs.microsoft.com/en-us/nuget/consume-packages/configuring-nuget-behavior) or have a look at [this](https://blogs.naxam.net/configure-nuget-package-sources-for-your-project-cd8b96397360) blog post.\n*)"},{"uri":"https://fslab.org/index.html","title":"The fslab documentation template\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: -\ncategory: hidden\nauthors: -\nindex: 0\n---\n*)\n\n(**\n# The fslab documentation template\n\nThis template scaffolds the necessary folder structure for FSharp.Formatting \nand adds custom styles in the **fslab** theme. \n\nThe provided stylesheet was compiled from sass (before uploading the nuget package) and\nuses the [Bulma](https://bulma.io/) CSS framework instead of bootstrap which is used by FSharp.Formatting per default.\n\n#### Table of contents \n\n- [Installation](#Installation)\n- [Usage](#Usage)\n- [Quick content rundown](#Quick-content-rundown)\n- [Creating new content](#Creating-new-content)\n- [Customization options](#Customization-options)\n    - [Style sheet options](#Style-sheet-options)\n    - [Inclusion of sample content](#Inclusion-of-sample-content)\n    - [Create notebooks](#Create-notebooks)\n\n\n## Installation\n\nThis template is available as a _dotnet new_ template (from [nuget](https://www.nuget.org/packages/FsLab.DocumentationTemplate/)):\n\n\u0060\u0060\u0060no-highlight\ndotnet new -i FsLab.DocumentationTemplate\n\u0060\u0060\u0060\n\n## Usage\n\nIf not already present, create a _local tool manifest_ in the root of your project that you want to write documentation for:\n\n\u0060\u0060\u0060no-highlight\ndotnet new tool-manifest\n\u0060\u0060\u0060\n\nThen, still in the root of your project, run:\n\n\u0060\u0060\u0060no-highlight\ndotnet new fslab-docs\n\u0060\u0060\u0060\n\n## Quick content rundown:\n\nThe default template initializes the following folder structure when you initialize it in the root of your project.\n\nSee [further below](#Customization-options) for command line customization options of the template.\n\n\u003Cpre\u003E\ndocs\n\u2502   index.fsx\n\u2502   _template.html\n|   _template.ipynb\n|   \n\u2502   0_Markdown-Cheatsheet.md\n\u2502   1_fsharp-code-example.fsx\n\u2502   2_inline-references.fsx\n\u2502   3_notebooks.fsx\n|\n\u251C\u2500\u2500\u2500content\n\u2502   fsdocs-custom.css\n\u2502\n\u251C\u2500\u2500\u2500img\n\u2502       favicon.ico\n\u2502       logo.png\n\u2502\n\u2514\u2500\u2500\u2500reference\n        _template.html\n\u003C/pre\u003E\n\n- \u0060index.fsx\u0060 is the file you are reading just now. It contains the very content you are reading at the moment \nin a markdown block indicated by \u0060(** *)\u0060 guards. It will be rendered as the root \u0060index.html\u0060 file of your documentation.\n\n- \u0060_template.html\u0060 is the root html scaffold (sidebar to the left, script and style loading) where all of the individual docs will be injected into\n\n- \u00600_Markdown-Cheatsheet.md\u0060 is a adaption of [this markdown cheat sheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) that shows how to write markdown and showcases the rendered equivalents. It can also be viewed in all its glory [here](https://fslab.org/docs-template/0_Markdown-Cheatsheet.html).\n\n- \u00601_fsharp-code-example.fsx\u0060 is a script file that showcases the syntax highlighting style for F# snippets. It can also be viewed in all its glory [here](https://fslab.org/docs-template/1_fsharp-code-example.html).\n\n- \u00602_inline-references.fsx\u0060 is a script file that explains how to use inline references and use Plotly.NET for charting. It can also be viewed in all its glory [here](https://fslab.org/docs-template/2_inline-references.html).\n\n- \u00603_notebooks.fsx\u0060 is a script file that showcases conditional content in documentation and how to use that to create dotnet interactive notebooks besides your html documentation. It can also be viewed in all its glory [here](https://fslab.org/docs-template/3_notebooks.html).\n\n- \u0060fsdocs-custom.css\u0060 contains the custom styling that applies the fslab styles.\n\n - the \u0060img\u0060 folder contains the fslab logo and favicon. replace these files (with the same names) to youse sours\n\n - \u0060reference/_template.html\u0060 is a slightly adapted version of the template above for the API documentation\n\n## Creating new content\n\n- run \u0060dotnet fsdocs watch --eval\u0060 to spawn a watcher and dev server that hosts your docs on http://localhost:8901/ (You currently will still have to refresh the page when you make changes to files)\n\n- add a new .md or .fsx file to the \u0060content\u0060 directory (or into a new subdirectory there)\n\n- the sidebar title for the document will be either the file name or, if existent, the first level 1 header in the file\n\n- when writing a .fsx file, code will automatically become syntax-highlighted code snippets. \n\n- use \u0060(** \u003Cmarkdown here\u003E *)\u0060 to guard markdown sections in .fsx files\n\n- use \u0060(*** include-value:\u003Cval name\u003E ***)\u0060 to include the value of a binding\n\n- use \u0060(*** include-it ***)\u0060 to include the evaluation of the previous snippet block \n\nFor more info please refer to the [FSharp.Formatting documentation](http://fsprojects.github.io/FSharp.Formatting/).\n\n\n## Customization options\n\n### Style sheet options\n\n\u0060\u0060\u0060no-highlight\n-s|--styles             Set the type of style content the template will initialize. For the sass file to work, you will have to download bulma\n\n        all             - sass file, compiled csss, and minified css\n\n        sass            - only include the sass file\n\n        minified        - only include the minified css file\n\n        css             - only include the compiled css file\n\n        Default:        css\n\u0060\u0060\u0060\n\n### Inclusion of sample content\n\n\u0060\u0060\u0060no-highlight\n-is|--include-samples   wether to include sample files in the generated content\n\n        bool            - Optional\n\n        Default:        true\n\u0060\u0060\u0060\n\n### Create notebooks\n\n\u0060\u0060\u0060no-highlight\n-in|--include-notebooks  wether to include the notebook template file\n        \n        bool            - Optional\n\n        Default:        true\n\u0060\u0060\u0060\n\n*)\n"}]